"""
Title:  : ç¬¬4ç«  Python-æ•¸æ“šçš„æ•´åˆã€æ¸…ç†èˆ‡è½‰æ›
File    : python_training_2025.01.22_pandas_matplotlib.py
Author  : Ming-Chang Lee
Date    : 2025.01.22
YouTube : https://www.youtube.com/@alan9956
RWEPA   : http://rwepa.blogspot.tw/
GitHub  : https://github.com/rwepa
Email   : alan9956@gmail.com
"""

# ğŸ˜€å¤§ç¶±ğŸ’

# 01.å­—ä¸²èˆ‡æ ¼å¼åŒ–è™•ç†
# 02.æ­£è¦è¡¨ç¤ºå¼
# 03.pandasæ¨¡çµ„ç°¡ä»‹
# 04.å°‡AQIè³‡æ–™é›†æ”¹ç‚ºPython pandasæ“ä½œ
# 05.matplotlib, seaborn, pandas, plotnine æ¨¡çµ„è¦–è¦ºåŒ–æ‡‰ç”¨
# 06.è¡ŒéŠ·æ¡ˆä¾‹æ‡‰ç”¨

##############################
# 01.å­—ä¸²èˆ‡æ ¼å¼åŒ–è™•ç†
##############################

# å­—ä¸²è¼¸å…¥ input

# input-ç¯„ä¾‹1
name = input("keyin your name?")
print(name)
type(name) # str

# input-ç¯„ä¾‹2
mynumbers = input("è¼¸å…¥2å€‹æ•¸å€¼, ä¸­é–“ä½¿ç”¨é€—è™Ÿå€éš”, è¨ˆç®—2å€‹æ•¸å€¼ç›¸åŠ çµæœ?")
print(mynumbers)
type(mynumbers)
len(mynumbers)

# æ€è€ƒé¡Œ: å¦‚ä½•è¨ˆç®—é€—è™Ÿå€éš”çš„äºŒå€‹æ•¸å€¼åŠ ç¸½

# å­—ä¸²(String)ç”±ä¸€å€‹(ä»¥ä¸Š)å­—å…ƒæ‰€çµ„æˆ
# å­—ä¸²å·¦å³äºŒå´é ˆä½¿ç”¨å–®å¼•è™Ÿæˆ–æ˜¯é›™å¼•è™Ÿ

# å­—ä¸²ç‰©ä»¶ https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str
# å­—ä¸²æ–¹æ³• https://docs.python.org/3/library/string.html

city = 'å°åŒ—å¸‚'
district = 'ä¿¡ç¾©å€'
road = 'ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ'

# ä½¿ç”¨ + å­—ä¸²ä¸²æ¥
city + district

address = city + district + road
print(address)

# æ•¸å€¼è½‰æ›ç‚ºå­—ä¸²
myinteger = 123
mystr = str(myinteger)
mystr
type(mystr)

# å­—ä¸²è½‰æ›ç‚ºæ•¸å€¼
mystr = "123.456"
myvalue = float(mystr)
myvalue
type(myvalue)

# å­—ä¸²æŒ‡æ¨™å­˜å–
address       # 'å°åŒ—å¸‚,ä¿¡ç¾©å€,ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ'
address[0]    # 'å°'
address[-1]   # 'è™Ÿ'
address[8:13] # 'ä¿¡ç¾©è·¯äº”æ®µ'

# ä½¿ç”¨ * å»ºç«‹é‡è¤‡å­—ä¸²
city   # 'å°åŒ—å¸‚'
5*city
city*5

# len é•·åº¦
len(address) # 15

# å­—ä¸²åˆ†å‰² â€“ split
# str.split(sep=None, maxsplit=-1)
# é è¨­åˆ†å‰² sep ç‚ºç©ºç™½å­—å…ƒ, maxsplit=-1 è¡¨ç¤ºæ²’åˆ†å‰²æ¬¡æ•¸é™åˆ¶

address = city + ',' + district + ',' + road
address
address.split(',') # é è¨­åˆ†å‰²å­—å…ƒç‚ºç©ºç™½å­—å…ƒ
address.split(',',  maxsplit = 1) # é è¨­åˆ†å‰²å­—å…ƒç‚ºç©ºç™½å­—å…ƒ

# å¯¦ä½œç·´ç¿’1
# ç·´ç¿’ mynumbers å­—ä¸²åˆ†å‰²ç‚ºäºŒå€‹æ•¸å€¼ä¸¦è¨ˆç®—æ•¸å€¼åŠ ç¸½.

# å­—ä¸²çµåˆ - join

city = "å°åŒ—å¸‚"
district = "ä¿¡ç¾©å€"
road = "ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ"
str1 = city + district + road
str1

''.join([city, district, road])

'-'.join([city, district, road])

mytuple = ("å°åŒ—å¸‚", "ä¿¡ç¾©å€", "ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ")
"".join(mytuple) # å°‡3å€‹å…ƒç´ ,åˆä½µç‚ºä¸€å€‹å…ƒç´ .
           
# å­—ä¸² if in (if not in)
txt = "One of the world's strictest lockdowns is lifting, but many are scared to go back to normal life."

if "scared" in txt:
    print("Find 'scared'") # å®Œå…¨æ¯”å°
    
if "scare" in txt:
    print("Find 'scare'")  # éƒ¨åˆ†å­—ä¸²ç›¸åŒ
    
if "Scare" in txt:
    print("Find 'Scare'")  # å€åˆ†å¤§å°å¯«

# åˆªé™¤å·¦å´æˆ–å³å´ç©ºç™½å­—å…ƒ strip (ä¸­é–“çš„å­—å…ƒä¸æœƒåˆªé™¤) 
# åˆªé™¤å·¦å´ç©ºç™½å­—å…ƒ lstrip 
# åˆªé™¤å³å´ç©ºç™½å­—å…ƒ rstrip
x = " RWEPA - Python å¤§æ•¸æ“šåˆ†æ\n "

x.strip()  # \n è¦–ç‚ºç©ºç™½å­—å…ƒè€ŒåŠ ä»¥åˆªé™¤
x.lstrip()
x.rstrip()

import string
string.whitespace # ' \t\n\r\x0b\x0c' \x0b:å°è¡¨æ©Ÿå‚ç›´å®šä½ç¬¦è™Ÿ, \x0c:æ›é ç¬¦è™Ÿ

x.strip("Python") # ä¸­é–“å­—å…ƒæœƒä¿ç•™
"Pythonå¤§æ•¸æ“šåˆ†æPython".strip("python") # æœ‰å€åˆ†å¤§å°å¯«
"Pythonå¤§æ•¸æ“šåˆ†æPython".strip("Python") # æœ‰å€åˆ†å¤§å°å¯«
"Pythonå¤§æ•¸æ“šåˆ†æPython".lstrip("python")
"Pythonå¤§æ•¸æ“šåˆ†æPython".rstrip("python")

# å­—ä¸²åˆ¤æ–· str.isxxx
"123".isdigit()                # æ•¸å­—digitsåŒ…æ‹¬ '0123456789'
"123".isalpha()                # æ•¸å­—ä¸æ˜¯è‹±æ–‡å­—æ¯
"alan9956".isalpha()           # è‹±æ–‡åŠ æ•¸å­—ä¸æ˜¯è‹±æ–‡å­—æ¯
"alan9956".isdigit()           # è‹±æ–‡åŠ æ•¸å­—ä¸æ˜¯æ•¸å­—
"!@#$%^&*()[]{}\|".isascii()   # åŠå‹ç¬¦è™Ÿæ˜¯ASCII
"ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™".isascii()   # æ—¥æœ¬å­—ä¸æ˜¯ASCII
"å¤§æ•¸æ“šåˆ†æ".isascii()          # ä¸­æ–‡å­—ä¸æ˜¯ASCII
"RWEPA".isupper()              # å¤§å¯«è‹±æ–‡å­—æ¯
"alan9956@gmail.com".islower() # å°å¯«è‹±æ–‡å­—æ¯

# å¯¦ä½œç·´ç¿’2
# è¨ˆç®— mystr å­—ä¸²ä¸­, ä¸å€åˆ†å¤§å°å¯«, è‹±æ–‡å­—æ¯å‡ºå‰æ¬¡æ•¸æœ€å¤šçš„å‰6åç‚ºä½•?
mystr = 'Scikit-learn is an Open source Machine Learning library that supports supervised and unsupervised learning.'
# æŠ€å·§: ä½¿ç”¨ collections.Counter æ–¹æ³•
# ç­”æ¡ˆç‚º n, e, i, r, s, a

# å­—ä¸²çš„æœå°‹
# find å›å‚³å­—ä¸²çš„ç´¢å¼•, æ‰¾ä¸åˆ°å›å‚³-1
mystr.find('Learning') # 39
mystr.find('bigdata') # -1

mystr.index('learn') # 7
mystr.index('bigdata') # ValueError: substring not found

for x in mystr:
    print(x)

# rfind å¾æœ€å¾Œé¢æŸ¥è©¢
mystr.rfind('learning') # 98

# å­—ä¸²å–ä»£ - replace
address = 'å°åŒ—å¸‚,ä¿¡ç¾©å€,ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ'
address.replace(',', '*') # 'å°åŒ—å¸‚*ä¿¡ç¾©å€*ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ'

# å­—ä¸²æ ¼å¼åŒ– - 4ç¨®æ–¹å¼

# å­—ä¸²æ ¼å¼åŒ– æ–¹æ³•1. æ—©æœŸä½¿ç”¨ %, èˆ‡ C èªè¨€ çš„ printf é¡ä¼¼
text = 'world'
print('Hello %s' % text) # Hello world

# å­—ä¸²æ ¼å¼åŒ– æ–¹æ³•2. str.format å‡½æ•¸

# 1å€‹åƒæ•¸
year = 2021
txt = "æˆ‘çš„åå­—æ˜¯ Alan, ç¾åœ¨æ˜¯ {} å¹´"
print(txt.format(year)) # æˆ‘çš„åå­—æ˜¯ Alan, ç¾åœ¨æ˜¯ 2021 å¹´

# å¤šå€‹åƒæ•¸
quantity = 1
item = "ç¾åœ‹Blue Yeti é›ªæ€ª USBéº¥å…‹é¢¨"
price = 5590

myorder = "æ„Ÿè¬æ‚¨è¨‚è³¼-->ç”¢å“åç¨±: {}, æ•¸é‡: {}, åƒ¹æ ¼: {} å…ƒ"
print(myorder.format(item, quantity, price))
# æ„Ÿè¬æ‚¨è¨‚è³¼-->ç”¢å“åç¨±: ç¾åœ‹Blue Yeti é›ªæ€ª USBéº¥å…‹é¢¨, æ•¸é‡: 1, åƒ¹æ ¼: 5590 å…ƒ

# å¤šå€‹åƒæ•¸-ä½¿ç”¨æŒ‡æ¨™
quantity = 1
item = "ç¾åœ‹Blue Yeti é›ªæ€ª USBéº¥å…‹é¢¨"
price = 5590

myorder = "æ„Ÿè¬æ‚¨è¨‚è³¼-->æ•¸é‡: {1}, ç”¢å“åç¨±: {0}, åƒ¹æ ¼: {2} å…ƒ"
print(myorder.format(item, quantity, price))
# æ„Ÿè¬æ‚¨è¨‚è³¼-->æ•¸é‡: 1, ç”¢å“åç¨±: ç¾åœ‹Blue Yeti é›ªæ€ª USBéº¥å…‹é¢¨, åƒ¹æ ¼: 5590 å…ƒ

# å­—ä¸²æ ¼å¼åŒ– æ–¹æ³•3. Formatted String Literal - å°‡é‹ç®—å¼ç½®æ–¼å­—ä¸²ä¹‹ä¸­

text = 'world'
print(f'Hello, {text}') # Hello, world

x = 10
y = 27
print(f'x + y = {x + y}') # x + y = 37

# å­—ä¸²æ ¼å¼åŒ– æ–¹æ³•4. Template String æ¨£æ¿å­—ä¸² - ä½¿ç”¨ string.Template

from string import Template
mytext = 'world'
t = Template('Hello $text') # ä½¿ç”¨1å€‹è®Šæ•¸ $text
type(t) # string.Template
t.substitute(text=mytext) # å°‡ textç½®æ›ç‚º mytext, 'Hello world'
# åƒè€ƒ: https://stackabuse.com/formatting-strings-with-the-python-template-class

##############################
# 02.æ­£è¦è¡¨ç¤ºå¼
##############################

# https://docs.python.org/3/library/re.html

# re.complile  å»ºç«‹æ­£è¦è¡¨ç¤ºå¼
# re.match     å¾é–‹å§‹ä½ç½®æª¢æŸ¥æ˜¯å¦åŒ¹é…. å¦‚æœæœ‰, å‰‡å›å‚³åŒ¹é…çµæœ. å¦‚æœæ²’æœ‰, å‰‡å›å‚³ None
# re.fullmatch å¾é–‹å§‹æˆ–çµæŸä½ç½®æª¢æŸ¥æ˜¯å¦åŒ¹é…
# re.search    å¾ä»»ä½•ä½ç½®é–‹å§‹æ¨¡å¼åŒ¹é…ï¼Œå›å‚³ç¬¬1ç­†
# re.findall   å›å‚³èˆ‡æ¨¡å¼åŒ¹é…çš„æ‰€æœ‰å­—ä¸²
# re.split     åˆ†å‰²
# re.sub       å–ä»£

# reç¯„ä¾‹-é›»è©±è™Ÿç¢¼
# åƒè€ƒ: Automate the Boring Stuff with Python, ç¬¬2ç‰ˆ.
# åƒè€ƒ: Python è‡ªå‹•åŒ–çš„æ¨‚è¶£ï½œæå®šé‡è¤‡ç‘£ç¢&å–®èª¿ç„¡èŠçš„å·¥ä½œ, ç¢å³°è³‡è¨Š, 2020.

# 02-8101-8800 (å€åŸŸç¢¼)2ç¢¼æ•¸å­—â€“4ç¢¼æ•¸å­—â€“4ç¢¼æ•¸å­—

# æ–¹æ³•1-ä½¿ç”¨ if, for
def isPhoneNumber(text):
    if len(text) != 12:
        return False  # not phone number-sized
    for i in range(0, 2):
        if not text[i].isdecimal():
            return False  # not an area code
    if text[2] != '-':
        return False  # does not have first hyphen
    for i in range(3, 7):
        if not text[i].isdecimal():
            return False  # does not have first 3 digits
    if text[7] != '-':
        return False  # does not have second hyphen
    for i in range(8, 12):
        if not text[i].isdecimal():
            return False  # does not have last 4 digits
    return True  # "text" is a phone number!

print('02-8101-8800is a phone number:')
print(isPhoneNumber('02-8101-8800'))

print('02-1234-ALAN is a phone number:')
print(isPhoneNumber('02-1234-ALAN'))

# æ–¹æ³•2-ä½¿ç”¨æ­£è¦è¡¨ç¤ºå¼
import re

phoneRegex = re.compile(r'\d\d-\d\d\d\d-\d\d\d\d') # å»ºç«‹æ­£è¦è¡¨ç¤ºå¼ç‰©ä»¶

mystr = '02-8101-8800'
myresult1 = phoneRegex.match(mystr)
myresult1

mystr = '02-8101-ALAN'
myresult2 = phoneRegex.match(mystr)
myresult2

# reç¯„ä¾‹-å­—ä¸²
mystr = 'Please call ALAN at 02-2822-5252. 02-1234-5678 is his office number. Try 02-87654321'

# match æ–¹æ³•
phoneRegex = re.compile(r'\d\d-\d\d\d\d-\d\d\d\d') # å»ºç«‹æ­£è¦è¡¨ç¤ºå¼ç‰©ä»¶

# æ–¹æ³•1
myresult = phoneRegex.match(mystr) # ä½¿ç”¨match, å¾æœ€å·¦å´æœå°‹.
print(myresult) # None è¡¨ç¤ºæ²’æœ‰æ‰¾åˆ°ç¬¦åˆå­—ä¸²

# æ–¹æ³•2
myresult1 = re.match(phoneRegex, mystr)
print(myresult1) # None,èˆ‡æ–¹æ³•1çµæœç›¸åŒ.

# fullmatch æ–¹æ³•, èˆ‡ matché¡ä¼¼,é™¤äº†æœ€å·¦å´å¦åŒ…æ‹¬æœ€å³å´æœå°‹
print(re.fullmatch(phoneRegex, mystr)) # None

# search æ–¹æ³•
phoneRegex = re.compile(r'\d\d-\d\d\d\d-\d\d\d\d')
phoneRegex.search(mystr) 
# æœ‰æ‰¾åˆ°1ç­†è³‡æ–™
# <re.Match object; span=(20, 32), match='02-2822-5252'>

phoneRegex = re.compile(r'\d{2}-\d{4}-\d{4}')
phoneRegex.search(mystr) # çµæœèˆ‡å‰é¢ç›¸åŒ

# findall æ–¹æ³•
phoneRegex.findall(mystr)
# ['02-2822-5252', '02-1234-5678']

# å¯¦ä½œç·´ç¿’3
mystr = 'éš¨è‘—æ­ç¾å¤šåœ‹è§£å°ï¼Œç‡ƒæ²¹è»Šã€é›»å‹•è»Šå¸‚æ³æ˜é¡¯å›æº«ï¼Œå¸¶å‹•è»Šç”¨é›»å­å¼·å‹éœ€æ±‚ï¼Œç›¸é—œé›¶çµ„ä»¶å» å‡ºè²¨ä¹Ÿé™¸çºŒå ±æ·ï¼Œè»Šé›»æ—ç¾¤ä»Š (13) æ—¥å†åº¦ç™¼å‹•çŒ›æ”»ï¼ŒåŒ…æ‹¬å¼·èŒ‚ (2481-TW)ã€å‡Œé€š (4952-TW)ã€æ¬£éŠ“ (3264-TW)ã€æ„›æ™® (6531-TW) ç­‰å¤šæª”ï¼Œç›¤ä¸­å‡äº®ç‡ˆæ¼²åœã€‚'
# ä»¥ mystr å­—ä¸²ç·´ç¿’, ä½¿ç”¨ findall æ‰¾å‡ºæ‰€æœ‰è‚¡ç¥¨ä»£ç¢¼
# çµæœç‚º ['2481-TW', '4952-TW', '3264-TW', '6531-TW']

# group æ–¹æ³•,ä½¿ç”¨å·¦å³æ‹¬è™Ÿ ()
mystr = '101å¤§æ¨“å®¢æœé›»è©±æ˜¯ 02-8101-8800'

phoneRegex = re.compile(r'(\d{2})-(\d{4}-\d{4})')
myresult = re.search(phoneRegex, mystr)
print(myresult) # match='02-8101-8800'

myresult.group(0) # å–å¾—å…¨éƒ¨è™Ÿç¢¼ '02-8101-8800'
myresult.group(1) # å–å¾—å€åŸŸè™Ÿç¢¼ '02'
myresult.group(2) # å–å¾—é›»è©±è™Ÿç¢¼ '8101-8800'

# groups æ–¹æ³•
areaCode, mainCode = myresult.groups()
areaCode # '02'
mainCode # '8101-8800'

# group æ–¹æ³•+è·³è„«å­—å…ƒ
mystr = '101å¤§æ¨“å®¢æœé›»è©±æ˜¯ (02)-8101-8800'
phoneRegex = re.compile(r'(\d{2})-(\d{4}-\d{4})')
myresult = re.search(phoneRegex, mystr)
print(myresult) # None-->æ‰¾ä¸åˆ°???

phoneRegex = re.compile(r'(\(\d{2}\))-(\d{4}-\d{4})')
myresult = re.search(phoneRegex, mystr)
print(myresult)

myresult.group(0) # å–å¾—å…¨éƒ¨è™Ÿç¢¼ '02-8101-8800'
myresult.group(1) # å–å¾—å€åŸŸè™Ÿç¢¼ '(02)'
myresult.group(2) # å–å¾—é›»è©±è™Ÿç¢¼ '8101-8800'

##############################
# 03.pandasæ¨¡çµ„ç°¡ä»‹
##############################

# https://pandas.pydata.org/
# Pandas æ¨¡çµ„æ˜¯ä¸€å€‹åŠŸèƒ½å¼·å¤§ä¸”éˆæ´»çš„è³‡æ–™åˆ†æå¥—ä»¶, ç‰¹åˆ¥é‡å°è¡¨æ ¼å¼è³‡æ–™é›†é€²è¡Œæ“ä½œ.

# ä¸»è¦åŠŸèƒ½
# 1.åºåˆ—å’Œè³‡æ–™æ¡†: æ”¯æ´å¤šç¨®æ•¸æ“šçµæ§‹, åŒ…æ‹¬:ä¸€ç¶­åºåˆ—(Series, é¡ä¼¼å·¥ä½œè¡¨çš„1è¡Œè³‡æ–™). äºŒç¶­è³‡æ–™æ¡†(DataFrame, é¡ä¼¼æ–¼æ•´å€‹å·¥ä½œè¡¨).
# 2.æ•¸æ“šæ“ä½œ: æä¾›äº†è¨±å¤šç”¨æ–¼è³‡æ–™æ“ä½œçš„æ–¹æ³•, ä¾‹å¦‚é¸æ“‡åˆ—,è¡Œ, æ’åº, éæ¿¾, ç¾¤çµ„.
# 3.æ•¸æ“šåˆ†æ: æ•´åˆäº†å¤šç¨®çµ±è¨ˆå’Œè¦–è¦ºåŒ–å·¥å…·, å¦‚è¨ˆç®—å¹³å‡å€¼ã€æ¨™æº–å·®ç­‰. 
# 4.è³‡æ–™è¦–è¦ºåŒ–: ç¹ªè£½åœ–è¡¨ç”¨çš„æ•£ä½ˆåœ–ã€ç·šåœ–ã€ç›’é¬šåœ–ç­‰æ•¸æ“šè¦–è¦ºæ•ˆæœ. https://pandas.pydata.org/docs/reference/plotting.html

# 10 minutes to pandas
# https://pandas.pydata.org/docs/user_guide/10min.html

# è¼‰å…¥2å¤§å¥—ä»¶ numpy, pandas
import numpy as np  # Python Scientific Computing Library
import pandas as pd # Python Data Analysis Library

##############################
# pandas åºåˆ—(Series)ç‰©ä»¶
##############################

# s = pd.Series(data, index=index)
# data åŒ…æ‹¬ä½¿ç”¨ array, Iterable, dict, scalar value
# åºåˆ—åŒ…æ‹¬æŒ‡æ¨™(Index) èˆ‡å€¼(Value), æŒ‡æ¨™æ¡ç”¨é è¨­æ•´æ•¸å‹æ…‹æŒ‡æ¨™ 0,1,2,...

# (1).Series - ä½¿ç”¨ ndarray
s = pd.Series(data = np.random.randn(5), index=["a", "b", "c", "d", "e"])
s
# a   -0.492604
# b   -0.073386
# c   -0.063632
# d    0.197128
# e    0.178333
# dtype: float64
type(s) # pandas.core.series.Series

# (2).Series -ä½¿ç”¨ Iterable - åºåˆ—(tuple)
s1 = pd.Series((1,3,5,np.nan,6,8))
s1

# (3).Series - ä½¿ç”¨ Iterable - ä¸²åˆ—(List)
s2 = pd.Series([1,3,5,np.nan,6,8])
s2

s1 == s2 # equality ç›¸ç­‰, æ¯”è¼ƒæ¯å€‹å…ƒç´ æ˜¯å¦ç›¸åŒ, å¤§éƒ¨åˆ†ä½¿ç”¨æ­¤åŠŸèƒ½.
s1 is s2 # identity ç›¸åŒ, æ¯”è¼ƒäºŒç‰©ä»¶æ˜¯å¦æŒ‡å‘åŒä¸€å€‹è¨˜æ†¶é«”

id(s1)
id(s2) # èˆ‡id(s1) ä¸ç›¸ç­‰

# "==" èˆ‡ "is" ("is not") æ‡‰ç”¨

# identity - ä½¿ç”¨ id å‡½æ•¸, æŸ¥çœ‹èªªæ˜ help(id). ç›¸åŒç¨‹å¼ id çµæœ,æ¯æ¬¡ä¸ä¸€å®šç›¸åŒ.
# https://realpython.com/python-is-identity-vs-equality/

a = 'Hello world'
b = 'Hello world'
a == b
a is b
id(a)
id(b)

# æ•´æ•¸ [-5 ~ 256] æœƒä½¿ç”¨ç›¸åŒè¨˜æ†¶é«”ä½å€åŠŸèƒ½
a = 256
b = 256
a == b   # True
a is b   # True
id(a)
id(b)

a = 1000
b = 1000
a == b   # True
a is b   # False
id(a)
id(b)

x1 = np.nan
x2 = np.nan
id(x1)
id(x2) # èˆ‡ä¸Šé¢çµæœç›¸åŒ
x1 == x2 # False
x1 is x2 # True

# (4).Series - ä½¿ç”¨ Iterable - å­—å…¸(Dict)
# åœ¨ pandas æ¨¡çµ„ä¹‹ä¸­, NaN è¡¨ç¤ºç‚º "not a number"
x = {"x1": 1, "x2": 2, "a": np.nan, "b": 3, "c": 4}
c = pd.Series(x)
c

# (5).Series - ä½¿ç”¨ scalar value
pd.Series(999.0, index=["a", "b", "c", "d", "e"])

##############################
# Series ä½¿ç”¨ ndarray-like æ“ä½œ
##############################
c
# x1    1.0
# x2    2.0
# a     NaN
# b     3.0
# c     4.0
# dtype: float64

c[0]              # 1.0
c[1]              # 2.0
c[-1]             # 4.0
c[:3]
# x1    1.0
# x2    2.0
# a     NaN
# dtype: float64

c[c > c.median()]
c[[1, 3, 2]]
np.exp(c)
c.dtype

# Series.array æ˜¯ pandasExtensionArray.
# ExtensionArray æ˜¯åŒ…æ‹¬ä¸€å€‹æˆ–å¤šå€‹ numpy.ndarray çš„ thin wrapperé¡åˆ¥
c.array      # å°‡ series è½‰æ›ç‚º PandasArray

c1 = c.to_numpy() # å°‡ series è½‰æ›ç‚º NumPy ndarray
c1

c2 = c.to_numpy
c2

c1 == c2
c1 is c2

##############################
# Series ä½¿ç”¨ dict-like æ“ä½œ
##############################
c

c['x1']
c['a'] = np.pi

'x1' in c

c.get("a")
c.get("e") # None

##############################
# pandas è³‡æ–™æ¡†(DataFrame)ç‰©ä»¶
##############################

# æ–¹æ³•1.å»ºç«‹æŒ‡æ¨™(index)èˆ‡å€¼(values), å°‡æŒ‡æ¨™èˆ‡å€¼åˆä½µç‚ºè³‡æ–™æ¡†.

# æ­¥é©Ÿ1-å»ºç«‹ DatetimeIndex ç‰©ä»¶
dates = pd.date_range('20210801', periods=6) # æ—¥æœŸæŒ‡æ¨™
dates
type(dates)

# æ­¥é©Ÿ2-å»ºç«‹ DataFrame
# æ¬„ä½åç¨±: A, B, C, D
df1 = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))
df1
type(df1)

# æ–¹æ³•2.ä½¿ç”¨å­—å…¸å»ºç«‹è³‡æ–™æ¡†
df2 = pd.DataFrame({ 'A' : 1.,
    'B' : pd.Timestamp('20210801'),
    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),
    'D' : np.array([3] * 4,dtype='int32'),
    'E' : pd.Categorical(["test","train","test","train"]),
    'F' : 'foo' })
df2

# dtypes: é¡¯ç¤ºå„æ¬„ä½çš„è³‡æ–™å‹æ…‹
df2.dtypes

# æ–¹æ³•3.ä½¿ç”¨ list of dicts å»ºç«‹è³‡æ–™æ¡†

# ä½¿ç”¨é è¨­æŒ‡æ¨™ 0, 1, 2,...
mydata = [{"a": 1, "b": 2}, {"a": 5, "b": 10, "c": 20}]
df3 = pd.DataFrame(mydata)
df3

# å®¢è£½åŒ–æŒ‡æ¨™
df4 = pd.DataFrame(mydata, index=["first", "second"])
df4

# æ–¹æ³•4.ä½¿ç”¨ dict of tuples å»ºç«‹è³‡æ–™æ¡†
# ä½¿ç”¨ tuples dictionary, å¯å»ºç«‹ MultiIndexed dataframe(éšå±¤å¼æŒ‡æ¨™è³‡æ–™æ¡†)
df5 = pd.DataFrame(
    {
        ("a", "b"): {("A", "B"): 1, ("A", "C"): 2},
        ("a", "a"): {("A", "C"): 3, ("A", "B"): 4},
        ("a", "c"): {("A", "B"): 5, ("A", "C"): 6},
        ("b", "a"): {("A", "C"): 7, ("A", "B"): 8},
        ("b", "b"): {("A", "D"): 10, ("A", "B"): 11},
    }
)
df5
type(df5)

# æ–¹æ³•5.ä½¿ç”¨ list of dataclasses å»ºç«‹è³‡æ–™æ¡†
# pandas 1.1.0 æ–°å¢åŠŸèƒ½, åƒè€ƒ PEP 557 -- Data Classes
# list of dataclasses é¡ä¼¼æ–¼ list of dictionaries
# https://www.python.org/dev/peps/pep-0557/

##############################
# è³‡æ–™æª¢è¦–
##############################
np.random.seed(123)
dates = pd.date_range('20210801', periods=6) # æ—¥æœŸæŒ‡æ¨™
df1 = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))
df1

# head é¡¯ç¤ºå‰ 5 ç­†è³‡æ–™, æ­¤åŠŸèƒ½èˆ‡ R é¡¯ç¤º 6 ç­†ä¸ç›¸åŒ.
df1.head()

df1.head(3) # é¡¯ç¤ºå‰ 3 ç­†è³‡æ–™

df1.tail()  # é¡¯ç¤ºå¾Œ 5 ç­†è³‡æ–™

# é¡¯ç¤ºæŒ‡æ¨™(index)
df1.index

# æ¬„åç¨±(columns)
df1.columns

# è³‡æ–™å€¼(values)
df1.values

# T è³‡æ–™è½‰ç½®, é¡ä¼¼å°‡åŸæœ¬é•·è³‡æ–™ (Long data), è½‰æ›ç‚ºå¯¬è³‡æ–™ (Wide data)
df1.T

##############################
# describe çµ±è¨ˆæ‘˜è¦(statistic summary)
##############################

# count å€‹æ•¸
# mean å¹³å‡å€¼
# std  æ¨™æº–å·® standard deviation, ä¸€èˆ¬å¸Œæœ›æ„ˆå°æ„ˆå¥½
# min  æœ€å°å€¼
# 25%  25ç™¾åˆ†ä½æ•¸
# 50%  50ç™¾åˆ†ä½æ•¸, ä¸­ä½æ•¸ median
# 75%  75ç™¾åˆ†ä½æ•¸ (quantile)
# max  æœ€å¤§å€¼

df1.describe()

##############################
# æ’åº
##############################

# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html

# (1).æ’åº sort_index

# axisç‚ºæ’åºçš„è»¸ï¼Œ0è¡¨ç¤º rows index(åˆ—æŒ‡æ¨™)ï¼Œ1è¡¨ç¤º columns index(è¡ŒæŒ‡æ¨™)
# ç•¶å°è³‡æ–™"åˆ—" é€²è¡Œæ’åºæ™‚ï¼Œaxiså¿…é ˆè¨­ç½®ç‚º0.
# df.sort(["A"]) æ–°ç‰ˆä¸æ”¯æ´ sort å‡½æ•¸, æ”¹ç”¨ sort_values æˆ– sort_index

# ascending =FALSE, å³éå¢æ˜¯FALSE, è¡¨ç¤ºéæ¸›æ˜¯TRUE, çµæœç‚ºD,C,B,A
df1.sort_index(axis=1, ascending=False)

# (2).æ’åº sort_values

# ä¾ç…§ B æ¬„å¤§å°, ç”±å°è‡³å¤§æ’åº (é è¨­å€¼æ˜¯éå¢)
df1.sort_values(by='B')

# ä¾ç…§ B æ¬„å¤§å°, æ”¹ç‚ºç”±å¤§è‡³å°æ’åº (éæ¸›)
df1.sort_values(by='B', ascending = False)

# ä¾ç…§ B æ¬„å¤§å°, å°‡ nan æ’åœ¨æœ€å‰é¢æˆ–æœ€å¾Œé¢
df1.iloc[2, 0] = np.nan
df1
df1.sort_values(by='A')
df1.sort_values(by='A', na_position = 'first')

# å¯¦ä½œç·´ç¿’4
# å»ºç«‹ mydf è³‡æ–™æ¡†ä¸¦é€²è¡ŒAæ¬„ä½éå¢, Bæ¬„ä½éæ¸›æ’åº.
#    A   B   C
# 0  1  10  aa
# 1  2  24  bb
# 2  2  26  cc
# 3  4   9  dd
# 4  2  29  aa

##############################
# è³‡æ–™åˆ—,è¡Œé¸å–
##############################
import numpy as np
import pandas as pd
np.random.seed(123)
dates = pd.date_range('20210801', periods=6) # æ—¥æœŸæŒ‡æ¨™
df1 = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))
df1

# é¸å–1è¡Œ
df1['A'] # å»ºè­°æ¡ç”¨æ­¤æ³•
df1.A

# é¸å–å¤šè¡Œ
df1[['A', 'B']]

df1

# é¸å–åˆ—, df[1:4]é¸å–æŒ‡æ¨™ç¬¬1è‡³ç¬¬3åˆ—(4-1=3), æ­¤åŠŸèƒ½èˆ‡ R ä¸åŒ.
df1[1:4]

##############################
# ä½¿ç”¨ iloc
##############################
# ä½¿ç”¨ iloc, å…¶ä¸­çš„ i è¡¨ç¤º index.
df1.iloc[2]      # ç¯©é¸ç¬¬2åˆ—
df1.iloc[2:5,]   # ç¯©é¸ç¬¬2åˆ—~ç¬¬4åˆ—(5-1=4)
df1.iloc[2:5,:]  # same as the above

df1.iloc[, 2]    # ERROR
df1.iloc[:, 2]   # OK
df1.iloc[:, 1:3] # OK, ç¬¬1è¡Œ~ç¬¬2è¡Œ(3-1=2)

df1.iloc[[1,2,4], [0,2]] # é¸å–ä¸é€£çºŒç¯„åœ
df1.iloc[2, 2]           # é©—è­‰é¸å–çµæœ

##############################
# ä½¿ç”¨ loc
##############################
# Boolean Indexing æŒ‡æ¨™çš„å¸ƒæ—é‹ç®—é¸å–
df1.loc[dates[2]]
df1.loc['20210803']

df1.loc[:, ['A','B']]
df1.loc[, 1:3]   # ERROR, æ”¹ç”¨ .iloc
df1.loc[:, 1:3]  # ERROR, æ”¹ç”¨ .iloc
df1.loc['20210803', ['A', 'B']]
df1.loc['20210802':'20210804', ['A', 'B']]

##############################
# ä½¿ç”¨ iat
##############################
df1.iat[2, 2] # é¸å–åˆ—, è¡Œçš„ä¸€å€‹å€¼, è¼¸å…¥åƒæ•¸ç‚ºä¸€å€‹æ•´æ•¸å€¼

##############################
# è³‡æ–™ç¯©é¸
##############################

# é‚è¼¯å€¼é¸å–
df1[df1 > 1.5]
df1[df1['A'] > 1.2]

# ä½¿ç”¨ isin - ç¯„ä¾‹1
df1[df1.index.isin(['2021-08-02', '2021-08-04'])]

# ä½¿ç”¨ isin - ç¯„ä¾‹2
df2 = df1.copy()
df2['E'] = ['one', 'one','two','three','four','three']
df2
df2[df2['E'].isin(['two','four'])]

# Missing Data éºæ¼å€¼ np.NaN (np.nan)
# R: ä½¿ç”¨ NA è¡¨ç¤º
df3 = df1.reindex(index=dates[0:4], columns=list(df1.columns) + ['E'])
df3.loc[dates[0]:dates[1],'E'] = 1
df3

# åˆ¤æ–·NaN
pd.isnull(df3)

# åˆªé™¤åˆ—ä¸­åŒ…æ‹¬ NaN
df3.dropna(how='any')

# å°‡éºæ¼å€¼å¡«å…¥å€¼
df3.fillna(value=999)

##############################
# åˆ—,è¡Œçš„åŒ¯ç¸½è¨ˆç®—
##############################
"""
A B C
1 5 
2 NaN 10
3 7 11
4 8 12
"""
df = pd.read_clipboard() # é¸å–ä¸Šè¿°ç¯„åœå…§è³‡æ–™, Ctrl + C
df
df.dtypes    
df.isnull()

# è¨ˆç®—æ¯è¡Œå¹³å‡
df.mean()

# è¨ˆç®—æ¯åˆ—å¹³å‡
df.mean(1)

# apply å°‡è³‡æ–™å¥—ç”¨è‡³å‡½æ•¸
df.apply(np.cumsum) # å„è³‡æ–™è¡Œ, é€²è¡Œé€åˆ—ç´¯è¨ˆåŠ ç¸½

##############################
# åˆ—åˆä½µ append, concat 
##############################

np.random.seed(123)
df = pd.DataFrame(np.random.randn(3, 4))
df

pieces = pd.DataFrame(np.random.randn(2, 4))
pieces

# append åˆ—åˆä½µ
df.append(pieces, ignore_index=True) # ERROR, v2.0æ–°ç‰ˆæ”¹ç”¨ concat

# concat åˆ—åˆä½µ, é¡ä¼¼ R çš„ rbind {base}
pieces1 = pd.DataFrame(np.random.randn(2, 4))
pieces1

pd.concat([df, pieces, pieces1]) # é è¨­å€¼ç‚ºä¿æŒåŸæœ‰æŒ‡æ¨™
pd.concat([df, pieces, pieces1], ignore_index=True) # æ”¹ç‚ºå¿½ç•¥æŒ‡æ¨™

##############################
# Grouping ç¾¤çµ„è¨ˆç®—
##############################

# ä¸‹è¼‰ Cars93.csv
# https://github.com/rwepa/DataDemo/blob/master/Cars93.csv

import numpy as np
import pandas as pd

# åŒ¯å…¥è³‡æ–™
df = pd.read_csv('Cars93.csv')
df
df.dtypes     # è³‡æ–™å‹æ…‹
df.columns    # æ¬„ä½åç¨±
df.describe() # çµæœé¡¯ç¤º ... è¡¨ç¤ºéš±è—çµæœ, countæœƒé¡¯ç¤ºmissing data
df.describe(include='all') # åŒ…æ‹¬æ‰€æœ‰æ¬„ä½(ä¾‹: object)

# pandas è¨­å®šé¡¯ç¤ºæ‰€æœ‰æ¬„ä½
# pd.set_option('display.expand_frame_repr', False)
# pd.set_option('display.max_columns', None)
# pd.set_option('display.max_rows', None)

# é¡¯ç¤ºæ‰€æœ‰çµæœ, ä¸æœƒæœ‰éš±è—è³‡æ–™, ä½†è³‡æ–™å¯èƒ½æœƒå·¦å³ä¸å°é½Š.
df.describe()

# é¡¯ç¤ºæ‰€æœ‰çµæœ, ä¸æœƒæœ‰éš±è—è³‡æ–™, ä½†è³‡æ–™å¯èƒ½æœƒå·¦å³ä¸å°é½Š.
df # çµè«–: Consoles\Restart kernel

##############################
# æ³¨æ„:  pandas åŒ¯å…¥ None è³‡æ–™å¾Œ, è‡ªå‹•è½‰æ›ç‚º NAN (Spyderç‰©ä»¶æª¢è¦–ç‚ºnan)
##############################

# https://www.datasciencebyexample.com/2022/08/24/2022-08-24-1/#google_vignette
# None: 'Missing data'
# NaN: 'Not a Number', undefined or unrepresentable values.

# åˆ¤æ–·æ˜¯å¦ç‚º nan
df['AirBags']
df['AirBags'].isna()
pd.isnull(df['AirBags'])

# ç¯©é¸é‡è¦ç‰¹å¾µå€¼(è®Šæ•¸)
df = df[['Manufacturer', 'Price', 'AirBags', 'Horsepower', 'Origin']]

# å‰5ç­†è³‡æ–™
df.head()

# åŒ…æ‹¬å­—ä¸²(object)èˆ‡æ•¸å€¼(float64),æ•´æ•¸(int64)è³‡æ–™
df.dtypes

# ç¾¤çµ„ - 1å€‹ç¶­åº¦
df_AirBags = df.groupby('AirBags')

type(df_AirBags) # pandas.core.groupby.generic.DataFrameGroupBy

print(df_AirBags.groups) # ç¾¤çµ„æ²’æœ‰é¡¯ç¤º nan

# ç¯©é¸ç¾¤çµ„
df_AirBags.get_group('Driver & Passenger')

# ç¾¤çµ„å¹³å‡
# å› ç‚ºè³‡æ–™åŒ…æ‹¬å­—ä¸²èˆ‡æ•¸å€¼å€‹ä¸åŒè³‡æ–™å‹æ…‹,å› æ­¤çµæœç•°å¸¸.
df_AirBags.mean()

# ç¾¤çµ„æ²’æœ‰é¡¯ç¤º nan ä¹‹å½™ç¸½é‹ç®—çµæœ
df[['Price', 'AirBags', 'Horsepower']].groupby('AirBags').mean()

# ç¾¤çµ„æœ‰é¡¯ç¤º nan ä¹‹å½™ç¸½é‹ç®—çµæœ
df[['Price', 'AirBags', 'Horsepower']].groupby('AirBags', dropna=False).mean()

# ä½¿ç”¨ agg - æ¯è¡Œè¨ˆç®—min
df_AirBags.agg('min')

df[['Price', 'AirBags', 'Horsepower']].groupby('AirBags', dropna=False).agg('min')

# ä½¿ç”¨ agg - æ¯è¡Œè¨ˆç®—max
df_AirBags.agg('max')

df[['Price', 'AirBags', 'Horsepower']].groupby('AirBags', dropna=False).agg('max')

# ç¾¤çµ„ - 2å€‹ç¶­åº¦
df_AirBagsOrigin = df.groupby(['AirBags', 'Origin'], dropna=False)

# ç¾¤çµ„å¤§å°
df_AirBagsOrigin.size()

df_AirBagsOrigin.min()

df_AirBagsOrigin.max()

df_AirBagsOrigin.mean() # TypeError: agg function failed [how->mean,dtype->object]

df_AirBagsOrigin.mean(numeric_only = True)

##############################
# æª”æ¡ˆåŒ¯å…¥ pandas
##############################

# pandas IO æ¨¡çµ„
# https://pandas.pydata.org/docs/user_guide/io.html

##############################
# å°‡ nan ä»¥ä¸­ä½æ•¸å¡«è£œ
##############################

import pandas as pd
print(pd.__version__) # 1.2.4

# ä¸‹è¼‰ marketing.csv è‡³ C:\pythondata\data è³‡æ–™å¤¾
# https://github.com/rwepa/DataDemo/blob/master/marketing.csv

# åŒ¯å…¥è³‡æ–™
marketing = pd.read_csv('marketing.csv')
marketing # 200*4

# è³‡æ–™æ‘˜è¦
marketing.describe()

# æœ‰NaN
marketing.isnull().sum()

marketing['facebook']

# å°‡ facebook è®Šæ•¸çš„ NaNè³‡æ–™, ä»¥ä¸­ä½æ•¸å¡«æ»¿
marketing['facebook'].fillna(marketing['facebook'].median, inplace = True)

# æ²’æœ‰NaN
marketing.isnull().sum()

print(marketing)
# RecursionError: maximum recursion depth exceeded

##############################
# åŒ¯å…¥ Excel æª”æ¡ˆ
##############################

# åŒ¯å…¥ Excel æª”æ¡ˆ, å…¨åœ‹è¨‚å–®æ˜ç´°.xlsx
# https://github.com/rwepa/DataDemo/blob/master/å…¨åœ‹è¨‚å–®æ˜ç´°.xlsx

sales = pd.read_excel(io = 'C:/mydata/å…¨åœ‹è¨‚å–®æ˜ç´°.xlsx', sheet_name = 'å…¨åœ‹è¨‚å–®æ˜ç´°')
sales # 8568*19
sales.head()

##############################
# åŒ¯å…¥ SAS æª”æ¡ˆ
##############################

# åŒ¯å…¥ SAS æª”æ¡ˆ, h_nhi_ipdte103.sas7bdat
# è³‡æ–™èªªæ˜: 103å¹´æ¨¡æ“¬å…¨æ°‘å¥ä¿è™•æ–¹åŠæ²»ç™‚æ˜ç´°æª”_è¥¿é†«ä½é™¢æª”
# è³‡æ–™ç­†æ•¸: 14297
# æ¬„ä½å€‹æ•¸: 80
# æª”æ¡ˆå¤§å°: 7.25MB
# https://github.com/rwepa/DataDemo/blob/master/h_nhi_ipdte103.sas7bdat

ipdate = pd.read_sas(filepath_or_buffer = 'C:/mydata/h_nhi_ipdte103.sas7bdat')
ipdate # 14297*80
ipdate.head()

##############################
# è³‡æ–™åŒ¯å‡º
##############################
df = pd.DataFrame({'å§“å': ['ALAN', 'LEE'],
                   'åœ°å€': ['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚'],
                   'å¹´è³‡': [10, 20]})
df
#      å§“å   åœ°å€  å¹´è³‡
# 0  ALAN  å°åŒ—å¸‚  10
# 1   LEE  æ–°åŒ—å¸‚  20

df.to_csv('data/df.csv', index = False) # ä¸­æ–‡äº‚ç¢¼

df.to_csv('data/df.csv', index = False, encoding = 'utf-8') # ä¸­æ–‡äº‚ç¢¼

df.to_csv('data/df.csv', index = False, encoding = 'utf_8_sig') # OK

##############################
# 04.å°‡AQIè³‡æ–™é›†æ”¹ç‚ºPython pandasæ“ä½œ
##############################

# title: æ—¥ç©ºæ°£å“è³ªæŒ‡æ¨™(AQI)
# source: https://data.gov.tw/dataset/40507
# https://github.com/rwepa/r_data_scientist/blob/main/r_training_2025.01.02_r_introduction.R#L453

# analysis:

# pandas plot line
# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html

import pandas as pd
import matplotlib.pyplot as plt

# urls = "aqx_p_434.csv"
urls = "https://raw.githubusercontent.com/rwepa/DataDemo/refs/heads/master/aqx_p_434.csv"

df = pd.read_csv(urls)

df                # AQIè³‡æ–™é›†
df.dtypes         # è³‡æ–™å‹æ…‹
df.columns        # æ¬„ä½åç¨±
df.describe()     # è³‡æ–™æ‘˜è¦
df.shape          # è³‡æ–™ç¶­åº¦ (1000, 11)
df.isnull().sum() # nanå€¼å€‹æ•¸è¨ˆç®—

# ç¯©é¸æ¿æ©‹è³‡æ–™é›†
df_Banqiao = df[df['sitename'] == 'æ¿æ©‹']

# ä¾ monitordate éå¢æ’åº
df_Banqiao = df_Banqiao.sort_values(by=['monitordate'])

df_Banqiao

# ç¯©é¸æ±æ­¢è³‡æ–™é›†
df_Xizhi = df[df['sitename'] == 'æ±æ­¢']

# ä¾ monitordate éå¢æ’åº
df_Xizhi = df_Xizhi.sort_values(by=['monitordate'])

df_Xizhi

# åˆä½µç‚ºä¸€å€‹è³‡æ–™æ¡†
df_BanqiaoXizhi = pd.DataFrame({'monitordate': df_Xizhi['monitordate'].values,
                                'Banqiao': df_Banqiao['aqi'].values,
                                'Xizhi': df_Xizhi['aqi'].values})
df_BanqiaoXizhi

ax = df_BanqiaoXizhi.plot.line(x='monitordate', 
                               y=['Banqiao', 'Xizhi'],
                               title='AQI - 2025.1.22@RWEPA')
ax.set_xlabel("Date")
ax.set_ylabel("AQI")
ax.tick_params(axis='x', labelsize=8)
plt.show()
# end

##############################
# 05.matplotlib, seaborn, pandas, plotnine æ¨¡çµ„è¦–è¦ºåŒ–æ‡‰ç”¨
##############################

##############################
# matplotlib è³‡æ–™è¦–è¦ºåŒ–æ‡‰ç”¨
##############################

# https://matplotlib.org/
  
# 11.1 matplotlibå¸¸ç”¨èªæ³•
import matplotlib.pyplot as plt
import numpy as np

N = 50
x = np.random.rand(N)
y = np.random.rand(N)
colors = np.random.rand(N)
area = np.pi * (15 * np.random.rand(N))**2  # åŠå¾‘ 0~15

# æ•£ä½ˆåœ– plt.scatter
plt.scatter(x, y, s=area, c=colors, alpha=0.5)
plt.savefig('random.plot.png')
plt.savefig('random.plot.pdf')
plt.show()

plt.scatter(x, y, s=500, c=colors, alpha=0.5)
plt.show()

# ç·šåœ– plt.plot
plt.plot(x,y)
plt.show()

plt.plot(sorted(x), y)
plt.show()

# example 1 - ç·šåœ–
plt.plot([1, 4, 9, 16])   # x è»¸: 0,1,2,3
plt.ylabel("Quality")
plt.show()

# example 2 - é»åœ–
plt.plot([1,2,3,4], [1,4,9,16], 'ro')  # r:red, o:circle marker
plt.axis([0, 6, 0, 20]) # set xlim and ylim
plt.show()

# example 3 - ä¸‰çµ„è³‡æ–™
t = np.arange(0., 5., 0.2) # ç­‰å·®ç´šæ•¸, å€é–“åŒ…æ‹¬å·¦å´å•Ÿå§‹å€¼, ä¸åŒ…æ‹¬å³å´çµæŸå€¼

# red dashes, blue squares and green triangles
plt.plot(t, t, 'r--', t, t**2, 'bs', t, t**3, 'g^')
plt.show()

# example 4 - äºŒåˆ—ä¸€è¡Œç¹ªåœ–

# 211: (nrow, ncol, plot_number) 
plt.subplot(211)     # ç¬¬1å€‹åœ–å½¢
plt.plot([1, 2, 3])

plt.subplot(212)     # ç¬¬2å€‹åœ–å½¢
plt.plot([1, 4, 9])

plt.subplot(211)     # åœ¨ç¬¬1å€‹åœ–å½¢ä¸Š, ç¹ªè£½åœ–å½¢æ¨™é¡Œ
plt.title('Easy as 1, 2, 3') # subplot 211 title
plt.show()

# example 5 - äºŒåˆ—ä¸€è¡Œç¹ªåœ–
def f(t):
    return np.exp(-t) * np.cos(2*np.pi*t)

t1 = np.arange(0.0, 5.0, 0.1)
t2 = np.arange(0.0, 5.0, 0.02)

plt.subplot(211)
plt.plot(t1, f(t1), 'bo', t2, f(t2), 'k')

plt.subplot(212)
plt.plot(t2, np.cos(2*np.pi*t2), 'r--')
plt.show()

# example 6 ç›´æ–¹åœ– (histogram)
import numpy as np
import matplotlib.pyplot as plt

# Fixing random state for reproducibility
np.random.seed(123)

mu, sigma = 100, 15
x = mu + sigma * np.random.randn(10000)

# ç›´æ–¹åœ–
n, bins, patches = plt.hist(x, 50, density=True, facecolor='g', alpha=0.75)
plt.xlabel('Smarts')
plt.ylabel('Probability')
plt.title('Histogram of IQ')
plt.text(80, 0.025, r'$\mu=100,\ \sigma=15$', size = 20)
plt.xlim(40, 160)
plt.ylim(0, 0.03)
plt.grid(True)
plt.show()

# example 7 å¤šåˆ—å¤šè¡Œç¹ªåœ–
fig = plt.figure()

# subplot:è¨­å®šåœ–å½¢ä½ç½®(åˆ—,è¡Œ,ç·¨è™Ÿ)
# fig.add_subplot(221)   #top left
# fig.add_subplot(222)   #top right
# fig.add_subplot(223)   #bottom left
# fig.add_subplot(224)   #bottom right 
# plt.show()

# plt.subplot()
# subplot(232) # 2åˆ—, 3è¡Œ, åœ–2ä½ç½®
# åœ–1 , åœ–2 , åœ–3
# åœ–4 , åœ–5 , åœ–6

# é è¨­ color æœ‰8å€‹
"""
b: blue
g: green
r: red
c: cyan
m: magenta
y: yellow
k: black
w: white
"""

# https://matplotlib.org/users/colors.html

# line style or marker
"""
'-'	  solid line style
'--'	  dashed line style
'-.'	  dash-dot line style
':'	  dotted line style
'.'	  point marker
','	  pixel marker
'o'	  circle marker
'v'	  triangle_down marker
'^'	  triangle_up marker
'<'	  triangle_left marker
'>'	  triangle_right marker
'1'	  tri_down marker
'2'	  tri_up marker
'3'	  tri_left marker
'4'	  tri_right marker
's'	  square marker
'p'	  pentagon marker
'*'	  star marker
'h'	  hexagon1 marker
'H'	  hexagon2 marker
'+'	  plus marker
'x'	  x marker
'D'	  diamond marker
'd'	  thin_diamond marker
'|'	  vline marker
'_'	  hline marker
"""

# æ°´é›· vs. å²©çŸ³ è¦–è¦ºåŒ–åˆ†æ

import pandas as pd
import matplotlib.pyplot as plt

target_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data"

# è³‡æ–™: 208åˆ—, 61è¡Œ
# X: V0-V59
# Y: V60
# ç¬¬61è¡Œ: R: rock  å²©çŸ³
# ç¬¬61è¡Œ: M: mine æ°´é›·

rocksVMines = pd.read_csv(target_url, header=None)

rocksVMines.columns = ['V' + str(i) for i in range (0, 61)]

rocksVMines
#          V0      V1      V2      V3      V4  ...     V56     V57     V58     V59  V60
# 0    0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032    R
# 1    0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044    R
# 2    0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078    R
# 3    0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117    R
# 4    0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094    R
# ..      ...     ...     ...     ...     ...  ...     ...     ...     ...     ...  ...
# 203  0.0187  0.0346  0.0168  0.0177  0.0393  ...  0.0065  0.0115  0.0193  0.0157    M
# 204  0.0323  0.0101  0.0298  0.0564  0.0760  ...  0.0034  0.0032  0.0062  0.0067    M
# 205  0.0522  0.0437  0.0180  0.0292  0.0351  ...  0.0140  0.0138  0.0077  0.0031    M
# 206  0.0303  0.0353  0.0490  0.0608  0.0167  ...  0.0034  0.0079  0.0036  0.0048    M
# 207  0.0260  0.0363  0.0136  0.0272  0.0214  ...  0.0040  0.0036  0.0061  0.0115    M

# print head and tail of data frame
print(rocksVMines.head())
print(rocksVMines.tail())

# print summary of data frame
summary = rocksVMines.describe()
print(summary)
#                V0          V1          V2  ...         V57         V58         V59
# count  208.000000  208.000000  208.000000  ...  208.000000  208.000000  208.000000
# mean     0.029164    0.038437    0.043832  ...    0.007949    0.007941    0.006507
# std      0.022991    0.032960    0.038428  ...    0.006470    0.006181    0.005031
# min      0.001500    0.000600    0.001500  ...    0.000300    0.000100    0.000600
# 25%      0.013350    0.016450    0.018950  ...    0.003600    0.003675    0.003100
# 50%      0.022800    0.030800    0.034300  ...    0.005800    0.006400    0.005300
# 75%      0.035550    0.047950    0.057950  ...    0.010350    0.010325    0.008525
# max      0.137100    0.233900    0.305900  ...    0.044000    0.036400    0.043900

# å¹³è¡Œåº§æ¨™è»¸ Parallel coordinates graph
for i in range(208):
    # assign color based on color based on "M" or "R" labels
    if rocksVMines.iat[i,60] == "M":
        pcolor = "red"
    else:
        pcolor = "blue"

    # plot rows of data as if they were series data
    dataRow = rocksVMines.iloc[i, 0:60]
    plt.rcParams["figure.figsize"] = (20, 15) #(å¯¬, é«˜)
    dataRow.plot(color=pcolor, alpha=0.5)
    # plot.figure(figsize=(16, 16))

plt.xlabel("Attribute Index")
plt.ylabel("Attribute Values")
plt.show()

##############################
# seaborn è³‡æ–™è¦–è¦ºåŒ–æ‡‰ç”¨
##############################

# https://seaborn.pydata.org/
# seaborn-data: https://github.com/mwaskom/seaborn-data

# Anaconda å·²ç¶“å®‰è£ seaborn æ¨¡çµ„
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style="ticks")

df = sns.load_dataset("iris")
df
#      sepal_length  sepal_width  petal_length  petal_width    species
# 0             5.1          3.5           1.4          0.2     setosa
# 1             4.9          3.0           1.4          0.2     setosa
# 2             4.7          3.2           1.3          0.2     setosa
# 3             4.6          3.1           1.5          0.2     setosa
# 4             5.0          3.6           1.4          0.2     setosa
# ..            ...          ...           ...          ...        ...
# 145           6.7          3.0           5.2          2.3  virginica
# 146           6.3          2.5           5.0          1.9  virginica
# 147           6.5          3.0           5.2          2.0  virginica
# 148           6.2          3.4           5.4          2.3  virginica
# 149           5.9          3.0           5.1          1.8  virginica
# [150 rows x 5 columns]

# æ•£ä½ˆåœ–çŸ©é™£ pairplot {seaborn}
# hue: coloråƒæ•¸
sns.pairplot(df, hue="species")
plt.show()

# diag_kind: å°è§’ç·šåœ–å½¢
sns.pairplot(df, hue="species", diag_kind="hist")
plt.show()

# kdeç¹ªåœ–
sns.pairplot(df, kind="kde")
plt.show()

# åŠ ä¸Šé¡è‰²,å½¢ç‹€
sns.pairplot(df, hue="species", markers=["o", "s", "D"])
plt.show()

# Question:
# import seaborn as sns 
# --> ImportError: DLL load failed: æ‰¾ä¸åˆ°æŒ‡å®šçš„ç¨‹åºã€‚

# Solution: å¯èƒ½æ˜¯ scipy æˆ–æ˜¯ numpy çš„ç‰ˆæœ¬å•é¡Œ, ç§»é™¤å¾Œé‡æ–°å®‰è£
# conda remove numpy
# conda install numpy
# conda install seaborn

##############################
# pandas è³‡æ–™è¦–è¦ºåŒ–æ‡‰ç”¨
##############################
# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html

##############################
# plotnine è³‡æ–™è¦–è¦ºåŒ–æ‡‰ç”¨
##############################

# https://plotnine.org/
# plotnine is an implementation of a grammar of graphics in Python based on ggplot2. 

# å®‰è£ plotnine æ¨¡çµ„
# pip install plotnine

from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap
from plotnine.data import mtcars

# æ•£ä½ˆåœ–
# wt å€¼æ„ˆå¤§, mpg æ„ˆå°(mpg: miles per US gallon in city)
(
    ggplot(mtcars, aes("wt", "mpg"))
    + geom_point()
)

# ç¾¤çµ„æ•£ä½ˆåœ– + é¡è‰²
(
    ggplot(mtcars, aes("wt", "mpg", color="factor(gear)"))
    + geom_point()
    #+ stat_smooth(method="lm")
    #+ facet_wrap("gear")
)

# ç¾¤çµ„æ•£ä½ˆåœ– + é¡è‰² + ç·šæ€§è¿´æ­¸
(
    ggplot(mtcars, aes("wt", "mpg", color="factor(gear)"))
    + geom_point()
    + stat_smooth(method="lm")
)

# ç¾¤çµ„æ•£ä½ˆåœ– + é¡è‰² + ç·šæ€§è¿´æ­¸ + åˆ†é¢(facet_wrap)
# æ‰€æœ‰åœ–å½¢ä¹‹X, Yè»¸åˆ»åº¦çš†ç›¸åŒ
(
    ggplot(mtcars, aes("wt", "mpg", color="factor(gear)"))
    + geom_point()
    + stat_smooth(method="lm")
    + facet_wrap("gear")
)
# åƒè€ƒ: https://r-graph-gallery.com/ggplot2-package.html

# å¯¦ä½œç·´ç¿’1
# ç·´ç¿’ mynumbers å­—ä¸²åˆ†å‰²ç‚ºäºŒå€‹æ•¸å€¼ä¸¦è¨ˆç®—æ•¸å€¼åŠ ç¸½.

# analysis: å­¸å“¡ç·´ç¿’ä½¿ç”¨å­—ä¸²åˆ†å‰² â€“ split

# å¯¦ä½œç·´ç¿’2
# è¨ˆç®— mystr å­—ä¸²ä¸­, ä¸å€åˆ†å¤§å°å¯«, è‹±æ–‡å­—æ¯å‡ºå‰æ¬¡æ•¸æœ€å¤šçš„å‰6åç‚ºä½•?
mystr = 'Scikit-learn is an Open source Machine Learning library that supports supervised and unsupervised learning.'
# æŠ€å·§: ä½¿ç”¨ collections.Counter æ–¹æ³•
# ç­”æ¡ˆç‚º n, e, i, r, s, a

# analysis:
mystr = 'Scikit-learn is an Open source Machine Learning learning library that supports supervised and unsupervised learning.'
# æŠ€å·§: ä½¿ç”¨ collections.Counter æ–¹æ³•

# æ­¥é©Ÿ1.è½‰æ›ç‚º list
mylist_tmp = list(mystr)

# æ­¥é©Ÿ2.åˆ¤æ–·æ˜¯å¦ç‚ºå­—æ¯, å¦‚æœæ˜¯å­—æ¯, è½‰æ›æˆå°å¯«
mylist = []
for x in mylist_tmp:
    if x.isalpha():
        mylist.append(x.lower())
mylist

# æ­¥é©Ÿ3.ä½¿ç”¨ counter è¨ˆç®—å­—æ¯ç™¼ç”Ÿæ¬¡æ•¸ä¸¦è½‰æ›ç‚º dict
import collections
mycounter = collections.Counter(mylist)
mycounter
mycounter.keys()
mycounter.values()

# æ­¥é©Ÿ4.æ’åºç™¼ç”Ÿæ¬¡æ•¸

# æœ€å¤§å€¼
max(mycounter, key=mycounter.get)

# ç”±å°è‡³å¤§æ’åº
sorted(mycounter, key=mycounter.get)

# ç”±å¤§è‡³å°æ’åº
sorted(mycounter, key=mycounter.get, reverse=True)

# ç”±å¤§è‡³å°æ’åº,ä¸¦åˆ—å‡º(key,value)çµæœ, æœ€å¤šç‚º n,e,i,r,s,a
mystrsort = sorted(mycounter.items(), key=lambda x: x[1], reverse=True)
mystrsort

# ç­”æ¡ˆç‚º n, e, i, r, s, a
mystrsort[0:6]

# å¯¦ä½œç·´ç¿’3
mystr = 'éš¨è‘—æ­ç¾å¤šåœ‹è§£å°ï¼Œç‡ƒæ²¹è»Šã€é›»å‹•è»Šå¸‚æ³æ˜é¡¯å›æº«ï¼Œå¸¶å‹•è»Šç”¨é›»å­å¼·å‹éœ€æ±‚ï¼Œç›¸é—œé›¶çµ„ä»¶å» å‡ºè²¨ä¹Ÿé™¸çºŒå ±æ·ï¼Œè»Šé›»æ—ç¾¤ä»Š (13) æ—¥å†åº¦ç™¼å‹•çŒ›æ”»ï¼ŒåŒ…æ‹¬å¼·èŒ‚ (2481-TW)ã€å‡Œé€š (4952-TW)ã€æ¬£éŠ“ (3264-TW)ã€æ„›æ™® (6531-TW) ç­‰å¤šæª”ï¼Œç›¤ä¸­å‡äº®ç‡ˆæ¼²åœã€‚'
# ä»¥ mystr å­—ä¸²ç·´ç¿’, ä½¿ç”¨ findall æ‰¾å‡ºæ‰€æœ‰è‚¡ç¥¨ä»£ç¢¼
# çµæœç‚º ['2481-TW', '4952-TW', '3264-TW', '6531-TW']

# analysis:
import re
stockRegex = re.compile(r'\d{4}-TW')
re.findall(stockRegex, mystr)

# å¯¦ä½œç·´ç¿’4
# å»ºç«‹ mydf è³‡æ–™æ¡†ä¸¦é€²è¡ŒAæ¬„ä½éå¢, Bæ¬„ä½éæ¸›æ’åº.
#    A   B   C
# 0  1  10  aa
# 1  2  24  bb
# 2  2  26  cc
# 3  4   9  dd
# 4  2  29  aa

# analysis:
import pandas as pd
mydf = pd.DataFrame(
    {'A': [1,2,2,4,2],
     'B': [10,24,26,9,29],
     'C': ['aa', 'bb', 'cc', 'dd', 'aa']})
mydf

mydf.sort_values(by=['A', 'B'], ascending = [True, False])
mydf # mydf å…§å®¹æ²’æœ‰æ›´æ”¹

# ä½¿ç”¨ inplace=True, mydf å…§å®¹å·²ç¶“æ›´æ”¹.
mydf.sort_values(by=['A', 'B'], ascending = [True, False],  inplace=True) 
mydf
# end

##############################
# 06.è¡ŒéŠ·æ¡ˆä¾‹æ‡‰ç”¨
##############################

# ç·šä¸Šäº¤æ˜“éŠ·å”®è³‡æ–™
# ç›´æ¥ github ä¸‹è¼‰: https://github.com/rwepa/DataDemo/blob/master/OnlineRetail.csv.zip
# ä¸‹è¼‰æª”åï¼šOnlineRetail.csv.zip
# è§£å£“ç¸®å¾Œæª”å: OnlineRetail.csv
# æª”æ¡ˆç­†æ•¸ï¼š541909åˆ—
# æ¬„ä½æ•¸ï¼š8æ¬„
# è§£å£“ç¸®å¾Œå¤§å°ï¼š43.4MB
# åŸå§‹è³‡æ–™ï¼šhttps://www.kaggle.com/vijayuv/onlineretail
# åƒè€ƒè³‡æ–™ï¼šhttps://towardsdatascience.com/data-driven-growth-with-python-part-1-know-your-metrics-812781e66a5b

##############################
# å®‰è£èˆ‡è¼‰å…¥å¥—ä»¶
##############################

# Anaconda å·²ç¶“å®‰è£ plotly æ¨¡çµ„

# è¼‰å…¥å¥—ä»¶
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from plotly.offline import plot # method 1: plot(fig)
import plotly.express as px # method 2: fig.show()
import plotly.graph_objs as go

# è¨­å®š plotlyç¹ªåœ–é è¨­é¡¯ç¤ºæ–¼ç€è¦½å™¨
import plotly.io as pio
pio.renderers.default='browser'

# åŒ¯å…¥CSVæª”æ¡ˆ
df = pd.read_csv('OnlineRetail.csv')

# å‰5ç­†è³‡æ–™
df.head(5)

# å¾Œ5ç­†è³‡æ–™
df.tail()

# æ¬„ä½åç¨±
df.columns

# è³‡æ–™æ‘˜è¦-æ•¸å€¼
df.describe()

# è³‡æ–™æ‘˜è¦-é¡åˆ¥
# Country å”¯ä¸€å€¼ç‚º38å€‹
df.describe(include = 'object')

# è³‡æ–™æ‘˜è¦-æ•¸å€¼ï¼‹é¡åˆ¥
df.describe(include = 'all')

# æ‰¾å‡ºæœ‰ç”¨çš„ç‰¹å¾µ(æœ‰æ„ç¾©çš„å±¬æ€§)
# Customer ID
# Unit Price
# Quantity
# Invoice Date

# å°‡ InvoiceDate æ¬„ä½è½‰æ›ç‚ºæ—¥æœŸ
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
df['InvoiceDate']

##############################
# æ–°å¢è©•ä¼°æ¬„ä½ InvoiceYearMonth ç™¼ç¥¨å¹´æœˆ
##############################

df['InvoiceYearMonth'] = df['InvoiceDate'].map(lambda date: 100*date.year + date.month)
df['InvoiceYearMonth']

##############################
# æ–°å¢è©•ä¼°æ¬„ä½ Revenue æ”¶å…¥
##############################

df['Revenue'] = df['UnitPrice'] * df['Quantity']
df['Revenue']

# å»ºç«‹å¹´æœˆç‚ºç¾¤çµ„,æ”¶å…¥å°è¨ˆè³‡æ–™
df_revenue = df.groupby(['InvoiceYearMonth'])['Revenue'].sum().reset_index()
df_revenue

# æ¯æœˆæ”¶å…¥çµ±è¨ˆåœ–
plot_data = [
    go.Scatter(
        x=df_revenue['InvoiceYearMonth'],
        y=df_revenue['Revenue'],
    )
]

plot_layout = go.Layout(
        xaxis={"type": "category"},
        title='åœ–1.æ¯æœˆæ”¶å…¥çµ±è¨ˆåœ–')

fig = go.Figure(data=plot_data, layout=plot_layout)

# method 1
plot(fig)

# method 2
fig.show()

# æ¯æœˆæ”¶å…¥å‘ä¸Šå¢åŠ è¶¨å‹¢.
# 2011å¹´2,4æœˆé”åˆ°æœ€ä½é».

##############################
# æ¯æœˆæ”¶å…¥è®ŠåŒ–ç™¾åˆ†æ¯”
##############################

# ä½¿ç”¨ pct_change() å‡½æ•¸è¨ˆç®—"æ¯æœˆæ”¶å…¥ç™¾åˆ†æ¯”è®ŠåŒ–"

df_revenue['MonthlyGrowth'] = df_revenue['Revenue'].pct_change()
df_revenue
# (560000.260-748957.020)/748957.020 = -0.252293

# æ¯æœˆæ”¶å…¥ç™¾åˆ†æ¯”è®ŠåŒ–çµ±è¨ˆåœ–
plot_data = [
    go.Scatter(
        x=df_revenue.query("InvoiceYearMonth < 201112")['InvoiceYearMonth'],
        y=df_revenue.query("InvoiceYearMonth < 201112")['MonthlyGrowth'],
    )
]

plot_layout = go.Layout(
        xaxis={"type": "category"},
        title='åœ–2.æ¯æœˆæ”¶å…¥ç™¾åˆ†æ¯”è®ŠåŒ–çµ±è¨ˆåœ–'
    )

fig = go.Figure(data=plot_data, layout=plot_layout)

fig.show()

##############################
# pandas è³‡æ–™è™•ç†æŠ€å·§
##############################

# 1.groupby ç¾¤çµ„å°è¨ˆ
# 2.rename æ¬„ä½é‡æ–°å‘½å
# 3.sort_values æ’åº

# 38å€‹åœ‹å®¶, å„ªå…ˆè€ƒæ…®åœ‹å®¶è³‡æ–™ç­†æ•¸æœ€å¤šè€… - United Kingdom
df_country = df.groupby(['Country']).size().reset_index()
df_country

# æ¬„ä½é‡æ–°å‘½å
df_country.rename(columns={0:'Count'}, inplace=True)

# æ’åº
df_country.sort_values(by=['Count'], ascending=False)

# å»ºç«‹ç¯©é¸ United Kingdom è³‡æ–™é›†
df_uk = df.query("Country=='United Kingdom'").reset_index(drop=True)
df_uk # 495478 rows Ã— 10 columns

##############################
# å»ºç«‹æ¯æœˆæ´»å‹•å®¢æˆ¶æ•¸çµ±è¨ˆè¡¨
##############################

# nunique: Count distinct observations over requested axis.
df_monthly_active = df_uk.groupby('InvoiceYearMonth')['CustomerID'].nunique().reset_index()
df_monthly_active

# æ¯æœˆæ´»å‹•å®¢æˆ¶æ•¸é•·æ¢åœ–
plot_data = [
    go.Bar(
        x=df_monthly_active['InvoiceYearMonth'],
        y=df_monthly_active['CustomerID'],
    )
]

plot_layout = go.Layout(
        xaxis={"type": "category"},
        title='åœ–3.æ¯æœˆæ´»å‹•å®¢æˆ¶æ•¸é•·æ¢åœ–'
    )

fig = go.Figure(data=plot_data, layout=plot_layout)

fig.show()
# 2011å¹´4æœˆå®¢æˆ¶æ•¸å¾3æœˆçš„ 923é™ä½è‡³ 817, æ¸›å°‘ (817-923)/923 = -11.5%

##############################
# æ¯æœˆæ¯ç­†è¨‚å–®å¹³å‡æ”¶å…¥
##############################

df_monthly_order_avg = df_uk.groupby('InvoiceYearMonth')['Revenue'].mean().reset_index()
df_monthly_order_avg

# æ¯æœˆæ¯ç­†è¨‚å–®å¹³å‡æ”¶å…¥é•·æ¢åœ–
plot_data = [
    go.Bar(
        x=df_monthly_order_avg['InvoiceYearMonth'],
        y=df_monthly_order_avg['Revenue'],
    )
]

plot_layout = go.Layout(
        xaxis={"type": "category"},
        title='åœ–4.æ¯æœˆæ¯ç­†è¨‚å–®å¹³å‡æ”¶å…¥é•·æ¢åœ–'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
fig.show()

##############################
# å»ºç«‹è©•ä¼°æ¬„ä½: æ–°å®¢æˆ¶, èˆŠå®¢æˆ¶
##############################

# å»ºç«‹ç¬¬1æ¬¡æ¶ˆè²»ä¹‹å®¢æˆ¶
# ä»¥å®¢æˆ¶ç·¨è™Ÿç‚ºç¾¤çµ„, è¨ˆç®— Min{ç™¼ç¥¨æ—¥æœŸ}
df_min_purchase = df_uk.groupby('CustomerID').InvoiceDate.min().reset_index()

# ä¿®æ”¹æ¬„ä½åç¨±
df_min_purchase.columns = ['CustomerID','MinPurchaseDate']
df_min_purchase

# æ–°å¢æ¬„ä½ - è½‰æ›æ—¥æœŸæ ¼å¼: è¥¿å…ƒå¹´æœˆ
df_min_purchase['MinPurchaseYearMonth'] = df_min_purchase['MinPurchaseDate'].map(lambda date: 100*date.year + date.month)

df_min_purchase # 3950 rows Ã— 3 columns

df_uk # 495478 rows Ã— 10 columns

# åˆä½µ {MinPurchaseDate, MinPurchaseYearMonth} è‡³ df_uk ä¹‹æœ€å³å´

df_uk = pd.merge(df_uk, df_min_purchase, on='CustomerID')

df_uk # 361878 rows Ã— 12 columns

# å»ºç«‹è©•ä¼°æ¬„ä½: å®¢æˆ¶å‹æ…‹ UserType, é è¨­å€¼ç‚º New
# å¦‚æœ InvoiceYearMonth å¤§æ–¼ MinPurchaseYearMonth,è¡¨ç¤ºä¹‹å‰ç‚ºç¾æœ‰å®¢æˆ¶, å°‡ UserType æ”¹ç‚º Existing

df_uk['UserType'] = 'New'

df_uk.loc[df_uk['InvoiceYearMonth'] > df_uk['MinPurchaseYearMonth'], 'UserType'] = 'Existing'

# æ–°,èˆŠå®¢æˆ¶çš„æ¯æœˆæ”¶å…¥å°è¨ˆ

# è¨ˆç®—æ¯æœˆæ–°èˆŠå®¢æˆ¶æ”¶å…¥å°è¨ˆ
df_user_type_revenue = df_uk.groupby(['InvoiceYearMonth','UserType'])['Revenue'].sum().reset_index()

# ç¯©é¸è³‡æ–™ä¸¦åˆªé™¤å‰,å¾Œè³‡æ–™
df_user_type_revenue = df_user_type_revenue.query("InvoiceYearMonth != 201012 and InvoiceYearMonth != 201112")
df_user_type_revenue

# ç¹ªåœ–
plot_data = [
    go.Scatter(
        x=df_user_type_revenue.query("UserType == 'Existing'")['InvoiceYearMonth'],
        y=df_user_type_revenue.query("UserType == 'Existing'")['Revenue'],
        name = 'Existing'
    ),
    go.Scatter(
        x=df_user_type_revenue.query("UserType == 'New'")['InvoiceYearMonth'],
        y=df_user_type_revenue.query("UserType == 'New'")['Revenue'],
        name = 'New'
    )
]

plot_layout = go.Layout(
        xaxis={"type": "category"},
        title='åœ–5.æ–°,èˆŠå®¢æˆ¶çš„æ¯æœˆæ”¶å…¥çµ±è¨ˆåœ–'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
fig.show()

##############################
# æ–°å®¢æˆ¶æ¯”ç‡ (New Customer Ratio)
##############################

# å»ºç«‹æ¯æœˆæ–°å®¢æˆ¶è³‡æ–™ä¸¦åˆªé™¤ NA
# æœ¬ä¾‹ä½¿ç”¨ unique å‡½æ•¸

df_user_ratio = df_uk.query("UserType == 'New'").groupby(['InvoiceYearMonth'])['CustomerID'].nunique()/df_uk.query("UserType == 'Existing'").groupby(['InvoiceYearMonth'])['CustomerID'].nunique()

# è¨­å®š index
df_user_ratio = df_user_ratio.reset_index()

# åˆªé™¤ NA
df_user_ratio = df_user_ratio.dropna()

df_user_ratio

# ç¹ªåœ–
# è€ƒæ…®2æœˆç‚ºæ–°å®¢æˆ¶,å› æ­¤æ¯”ä¾‹è¼ƒé«˜.

plot_data = [
    go.Bar(
        x=df_user_ratio.query("InvoiceYearMonth>201101 and InvoiceYearMonth<201112")['InvoiceYearMonth'],
        y=df_user_ratio.query("InvoiceYearMonth>201101 and InvoiceYearMonth<201112")['CustomerID'],
    )
]

plot_layout = go.Layout(
        xaxis={"type": "category"},
        title='åœ–6.æ–°å®¢æˆ¶æ¯”ç‡çµ±è¨ˆåœ–'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
fig.show()

##############################
# æ¯æœˆå®¢æˆ¶ä¿ç•™ç‡ (Monthly Retention Rate)
##############################

# æ¯æœˆå®¢æˆ¶ä¿ç•™ç‡=ä¸Šå€‹æœˆä»¥å‰ä¿ç•™çš„å®¢æˆ¶/ç¸½æ´»èºå®¢æˆ¶æ•¸

# è¨ˆç®—æ´»èºå®¢æˆ¶æ•¸, ä¾æ“š {CustomerID, InvoiceYearMonth}ç‚ºç¾¤çµ„, è¨ˆç®—æ”¶å…¥ç¸½è¨ˆ.

df_user_purchase = df_uk.groupby(['CustomerID','InvoiceYearMonth'])['Revenue'].sum().reset_index()
df_user_purchase

# ä½¿ç”¨ crosstab (äº¤å‰è¡¨) å»ºç«‹å®¢æˆ¶ä¿ç•™çŸ©é™£, crosstab é è¨­ä½¿ç”¨"ç™¼ç”Ÿæ¬¡æ•¸"

df_retention = pd.crosstab(df_user_purchase['CustomerID'], df_user_purchase['InvoiceYearMonth']).reset_index()

df_retention

# å»ºç«‹å­—å…¸ç‰©ä»¶, è¨˜éŒ„æœˆä»½, ç¸½æ´»èºå®¢æˆ¶æ•¸, ä¿ç•™å®¢æˆ¶æ•¸
months = df_retention.columns[2:]
retention_array = []

for i in range(len(months)-1):
    retention_data = {}
    selected_month = months[i+1]
    prev_month = months[i]
    retention_data['InvoiceYearMonth'] = int(selected_month)
    retention_data['TotalUserCount'] = df_retention[selected_month].sum()
    retention_data['RetainedUserCount'] = df_retention[(df_retention[selected_month]>0) & (df_retention[prev_month]>0)][selected_month].sum()
    retention_array.append(retention_data)
retention_array

# è½‰æ›ç‚ºè³‡æ–™æ¡†
df_retention = pd.DataFrame(retention_array)
df_retention

# è¨ˆç®—ä¿ç•™ç‡
df_retention['RetentionRate'] = df_retention['RetainedUserCount']/df_retention['TotalUserCount']
df_retention

# ç¹ªåœ–
plot_data = [
    go.Scatter(
        x=df_retention.query("InvoiceYearMonth<201112")['InvoiceYearMonth'],
        y=df_retention.query("InvoiceYearMonth<201112")['RetentionRate'],
        name="organic"
    )
    
]

plot_layout = go.Layout(
        xaxis={"type": "category"},
        title='åœ–7.æ¯æœˆå®¢æˆ¶ä¿ç•™ç‡çµ±è¨ˆåœ–'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
fig.show()

##############################
# open/writeå¯¦ä½œç·´ç¿’èˆ‡åƒè€ƒè§£ç­”
##############################

# é¡Œç›®åƒè€ƒæœ€å¾Œä¸€åˆ—ç¨‹å¼ç¢¼
# https://github.com/rwepa/r_data_scientist/blob/main/python_training_2025.01.07_python_introduction.ipynb

# æª”æ¡ˆæ—¥æœŸæ™‚é–“è™•ç†
# https://www.kaggle.com/shawon10/web-log-dataset
# æª”æ¡ˆåç¨±: weblog.csv
# æ¬„ä½å€‹æ•¸:4
# è³‡æ–™ç­†æ•¸:16007
# IP	Time	URL	Staus
# 10.128.2.1	[29/Nov/2017:06:58:55	GET /login.php HTTP/1.1	200
# 10.128.2.1	[29/Nov/2017:06:59:02	POST /process.php HTTP/1.1	302
# 10.128.2.1	[29/Nov/2017:06:59:03	GET /home.php HTTP/1.1	200

# ä¸‹è¼‰ https://github.com/rwepa/DataDemo/blob/master/weblog.csv

# ç·´ç¿’ä½¿ç”¨ open, read, datetime, re ç­‰è™•ç†æŠ€è¡“(ä¸å¯ä½¿ç”¨ pandas),è¨ˆç®—ä¸‹åˆ—3å€‹æ™‚æ®µçš„è³‡æ–™ç­†æ•¸
# 06:00-14:00, 14:00-22:00, 22:00-06:00
# analysis:

import os
from datetime import datetime

# æ–°å¢ C:\mydata è³‡æ–™å¤¾
os.chdir("C:/mydata") # è®Šæ›´å·¥ä½œç›®éŒ„
myfile = "weblog.csv"

##############################
# Part 1.åˆ†ææ¨¡å¼
##############################

# è®€å–è³‡æ–™ readlines
with open(myfile, "r") as infile:
    for line in infile:
        print(line)

# è§£ææ—¥æœŸ,æ™‚é–“-æ–¹æ³•1, å–ä»£"["å­—å…ƒç‚ºç©ºç™½
mystr = "10.128.2.1,[29/Nov/2017:06:58:55,GET /login.php HTTP/1.1,200"
mystr.split(",")
mystr.split(",")[1] # '[29/Nov/2017:06:58:55'
mystrDatetime = mystr.split(",")[1].replace("[", "")
mystrDatetime # '29/Nov/2017:06:58:55'

# str è½‰æ›ç‚º datetime
format_string = "%d/%b/%Y:%H:%M:%S"
x = datetime.strptime(mystrDatetime, format_string)
x
x.hour # datetime å–å‡ºå°æ™‚
str(x) # datetime è½‰æ›ç‚º str

# è§£ææ—¥æœŸ,æ™‚é–“-æ–¹æ³•2, ä¿ç•™"["å­—å…ƒ
datetime.strptime("[29/Nov/2017:06:58:55", "[%d/%b/%Y:%H:%M:%S")

# æ¸¬è©¦ IndexError
'Dec'.split(",")[1].replace("[", "")

# æ¸¬è©¦ ValueError
datetime.strptime('Dec', format_string)

# ä½¿ç”¨ try
try:
    datetime.strptime('Dec', format_string)
    'Dec'.split(",")[1].replace("[", "")
except (ValueError, IndexError):
        print('Error')
else:
    print("OK")

# 06:00-14:00, 14:00-22:00, 22:00-06:00
# period1, period2, period3(å·¦å´æœ‰ç­‰è™Ÿ,å³å´æ²’æœ‰ç­‰è™Ÿ)

##############################
# Part 2.æ•´åˆç‰ˆæœ¬
##############################

period1 = list()
period2 = list()
period3 = list()

with open(myfile, "r") as infile:
    next(infile) # ç¬¬1åˆ—ç‚ºæ¨™é¡Œåˆ—, å…ˆè·³éä¸¦åŸ·è¡Œä¸‹ä¸€ç­†è³‡æ–™
    format_string = "%d/%b/%Y:%H:%M:%S" # str è½‰æ›ç‚º datetime
    for data in infile:
        try:
            tmp = data.split(",")[1].replace("[", "") # å–ä»£
            mydatetime = datetime.strptime(tmp, format_string) # è½‰æ›ç‚º datatime
            mydatetimeHour = mydatetime.hour # å–å‡ºå°æ™‚
        except (ValueError, IndexError): # ä½¿ç”¨ except è™•ç†éŒ¯èª¤
            pass
        else:
            # print(tmp)
            # print(str(mydatetimeHour))
            if mydatetimeHour >= 22:
                period3.append(str(mydatetimeHour))
            elif mydatetimeHour >= 14 and mydatetimeHour < 22:
                period2.append(str(mydatetimeHour))
            elif mydatetimeHour >= 6 and mydatetimeHour < 14:
                period1.append(str(mydatetimeHour))
            elif mydatetimeHour < 6:
                period3.append(str(mydatetimeHour))
    print('...è³‡æ–™è®€å–å®Œæˆ')
# end for reading
            
##############################
# Part 3.çµè«–
##############################
print(period1)
print(period2)
print(period3)

periodAnalysis = {'06:00-14:00': len(period1),
                  '14:00-22:00': len(period2),
                  '22:00-06:00': len(period3)}
periodAnalysis 
# {'06:00-14:00': 3250, '14:00-22:00': 11244, '22:00-06:00': 1295}
sum(periodAnalysis.values()) # 15789, è«‹é©—è­‰æ­£ç¢ºæ€§!
# end

# åƒè€ƒè³‡æ–™ -----

# RWEPA
# http://rwepa.blogspot.com/

# Rè³‡æ–™ç§‘å­¸å®¶
# https://github.com/rwepa/r_data_scientist

# Rå…¥é–€è³‡æ–™åˆ†æèˆ‡è¦–è¦ºåŒ–(ä»˜è²»,å­—å¹•)
# https://mastertalks.tw/products/r?ref=MCLEE

# Rå•†æ¥­é æ¸¬èˆ‡æ‡‰ç”¨(ä»˜è²»,å­—å¹•)
# https://mastertalks.tw/products/r-2?ref=MCLEE

# Pythonè³‡æ–™ç§‘å­¸å®¶
# https://github.com/rwepa/python_data_scientist

# Python ç¨‹å¼è¨­è¨ˆ-ææ˜æ˜Œ <å…è²»é›»å­æ›¸>
# http://rwepa.blogspot.com/2020/02/pythonprogramminglee.html

# SQLå¯¦ä½œç­
# https://erp.mgt.ncu.edu.tw/sql-practical-course/

# Streamlitäº’å‹•å¼è³‡æ–™æ‡‰ç”¨ç­
# https://erp.mgt.ncu.edu.tw/streamlit-application-course/
# end
# è¾›è‹¦å•¦,å®ŒæˆPythonç¨‹å¼ä¹‹æ—…~~
