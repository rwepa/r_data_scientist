# file     : r_data_science_advcanced_04_predictive_modelling.R
# title    : 4.é æ¸¬æ¨¡å‹
# author   : Ming-Chang Lee
# date     : 2025.08.02
# YouTube  : https://www.youtube.com/@alan9956
# RWEPA    : http://rwepa.blogspot.tw/
# GitHub   : https://github.com/rwepa
# Email    : alan9956@gmail.com

# ğŸŒ¸ å¤§ç¶± -----
# 4.1 èªè­˜lmèˆ‡glmå‡½æ•¸
# 4.1.1 æ©Ÿå™¨å­¸ç¿’ç°¡ä»‹
# 4.1.2 CRISP-DMæ¨™æº–æµç¨‹
# 4.1.3 æ¨¡å‹ç¸¾æ•ˆè©•ä¼°
# 4.1.4 lmå‡½æ•¸
# 4.1.5 glmå‡½æ•¸
# 4.2 ç†Ÿæ‚‰é–‹æ”¾è³‡æ–™é›†æ–¼lmèˆ‡glmæ‡‰ç”¨
# 4.3 æ·±åº¦å­¸ç¿’æ‡‰ç”¨

# ğŸŒ¸ å¥—ä»¶ç¸½è¦½ -----
# AER # Affairs è³‡æ–™é›†
# collapsibleTree # å¯æ‘ºç–Šæ¨¹ç‹€è¦–è¦ºåŒ–
# devtools        # å®‰è£å¥—ä»¶å·¥å…·
# ggflowchart     # ç¹ªè£½æµç¨‹åœ–
# ggplot2         # åœ–å½¢æ–‡æ³•ç¹ªåœ–
# htmlwidgets     # å„²å­˜ç‚ºHTML
# neuralnet       # é¡ç¥ç¶“ç¶²è·¯
# NeuralNetTools  # é¡ç¥ç¶“ç¶²è·¯è¦–è¦ºåŒ–å·¥å…·
# nnet            # é¡ç¥ç¶“ç¶²è·¯
# party           # æ±ºç­–æ¨¹
# randomForest    # éš¨æ©Ÿæ£®æ—æ³•
# RColorBrewer    # èª¿è‰²ç›¤

# ğŸŒ¸ 4.1 èªè­˜lmèˆ‡glmå‡½æ•¸ -----

# èªè­˜è‡ªè®Šæ•¸èˆ‡åæ‡‰è®Šæ•¸

# https://github.com/rwepa/DataDemo?tab=readme-ov-file#variables

# X: è‡ªè®Šæ•¸, ç¨ç«‹è®Šæ•¸ independent variable, é æ¸¬è®Šé‡ predictor variable, è§£é‡‹è®Šé‡ explanatory variable, å…±è®Šé‡ covariate.

# Y: åæ‡‰è®Šæ•¸ response variable, å› è®Šæ•¸, ä¾è®Šæ•¸, æ‡‰è®Šæ•¸, è¢«è§£é‡‹è®Šæ•¸ dependent variable, çµæœè®Šæ•¸ outcome variable.

# è€ƒé‡è‡ªè®Šæ•¸èˆ‡åæ‡‰è®Šæ•¸ä¹‹é–“å…·æœ‰ç·šæ€§é—œä¿‚, å³ Y=f(X)

# lmå‡½æ•¸ä¹‹ä¸»è¦åŠŸèƒ½æ˜¯æ“¬åˆç·šæ€§æ¨¡å‹(Fitting Linear Models), å¯ç”¨æ–¼å–®ä¸€è®Šæ•¸ä¹‹ç°¡å–®ç·šæ€§æ¨¡å‹(Single regression model)èˆ‡å¤šè®Šæ•¸è¤‡è¿´æ­¸æ¨¡å‹(Multiple linear regression / Multivariable linear regression).

# ç·šæ€§æ¨¡å‹ä¸­å–®ä¸€è®Šæ•¸æˆ–å¤šè®Šæ•¸è¡¨ç¤ºè‡ªè®Šæ•¸(X)çš„å€‹æ•¸å¯ä»¥ç‚º1å€‹æˆ–å¤§æ–¼ç­‰æ–¼1å€‹.

# ç·šæ€§æ¨¡å‹ä¸­çš„åæ‡‰è®Šæ•¸(Y)ä¸€èˆ¬ç‚ºä¸€å€‹è®Šæ•¸.

# ğŸŒ¸ 4.1.1 æ©Ÿå™¨å­¸ç¿’ç°¡ä»‹ -----

library(ggflowchart)  # ç¹ªè£½æµç¨‹åœ–
library(RColorBrewer) # èª¿è‰²ç›¤
library(ggplot2)      # åœ–å½¢æ–‡æ³•ç¹ªåœ–

display.brewer.all(colorblindFriendly=TRUE) # é¡¯ç¤ºæ‰€æœ‰èª¿è‰²ç›¤
display.brewer.pal(n=8, name="Set2")        # é¡¯ç¤ºç‰¹å®šèª¿è‰²ç›¤
datacol <- brewer.pal(n=5, name="Set2")     # ä½¿ç”¨Set2èª¿è‰²ç›¤

# å»ºç«‹æµç¨‹åœ–å…ƒç´ 
ai <- "äººå·¥æ™ºæ…§1950~"
dm <- "è³‡æ–™æ¢å‹˜1960~"
ml <- "æ©Ÿå™¨å­¸ç¿’1980~"
dl <- "æ·±åº¦å­¸ç¿’2006~"
gl <- "ç”Ÿæˆå­¸ç¿’2020,2022(ChatGPT)~"

# å»ºç«‹è³‡æ–™é›†
df <- tibble::tibble(from = c(ai, dm, ml, dl),
                     to   = c(dm, ml, dl, gl))

# é¡¯ç¤ºäººå·¥æ™ºæ…§ç™¼å±•å²
ggflowchart(df, colour = datacol, text_size = 8) +
  ggtitle("äººå·¥æ™ºæ…§ç™¼å±•å²") +
  theme(plot.title = element_text(hjust = 0.5, size = 30, face = "bold"))

# é‡è¦é‡Œç¨‹ç¢‘:

# 1.äººå·¥æ™ºæ…§ (AI, artificial intelligence)1950~
# 1943å¹´: ç¾åœ‹æ•¸å­¸å®¶ Walter Pittså’Œå¿ƒç†å­¸å®¶ Warren McCullochæå‡ºäººå·¥ç¥ç¶“å…ƒ.
# 1957å¹´: ç¾åœ‹å¿ƒç†å­¸å®¶ Frank Rosenblatt æå‡ºäº†æ„ŸçŸ¥å™¨(Perceptron). 

# 2.è³‡æ–™æ¢å‹˜ (DM, data mining)1960~
# https://en.wikipedia.org/wiki/Data_mining
# ä»¥æ‰‹å‹•åˆ†æç‚ºä¸», æ‡‰ç”¨åœ¨äººå£æ™®æŸ¥, å•†æ¥­å¸³å‹™ç­‰.
# ä½¿ç”¨æŠ€è¡“åŒ…æ‹¬æ•˜è¿°æ€§çµ±è¨ˆ, è®Šç•°æ•¸åˆ†æ, è¿´æ­¸åˆ†æç­‰åŸºç¤çµ±è¨ˆæ¨è«–æ–¹æ³•.
# è³‡æ–™æ¢å‹˜ç›®æ¨™æ˜¯æè¿°èˆ‡è§£é‡‹è³‡æ–™, è€Œéé€²è¡Œé æ¸¬, æ•´é«”æ˜¯æ‰¾å‡ºæ¨£å¼(Patterns).
# 1970å¹´ç™¼å±•å‡ºIBM-DB2é—œè¯å¼è³‡æ–™åº«.

# 3.æ©Ÿå™¨å­¸ç¿’ (ML, machine learning)1980~
# https://en.wikipedia.org/wiki/Machine_learning
# é–‹å§‹åŠ å…¥æ¼”ç®—æ³•ä¹‹æ‡‰ç”¨.
# 1980å¹´å¤šå±¤é¡ç¥ç¶“ç¶²è·¯å¤±æ•—, æ·ºå±¤æ©Ÿå™¨å­¸ç¿’æ–¹æ³•(æ”¯æŒå‘é‡æ©ŸSVMç­‰)èˆˆèµ·.
# æ©Ÿå™¨å­¸ç¿’ç›®æ¨™æ˜¯å»ºç«‹æ¨¡å‹(Model)ä¸¦é æ¸¬æœªä¾†äº‹ä»¶.
# æ©Ÿå™¨å­¸ç¿’çš„ä¸‰å¤§æŠ€è¡“:
# [1].ç›£ç£å¼å­¸ç¿’ (Supervised learning): Telling the algorithm what to predict
# [2].éç›£ç£å¼å­¸ç¿’ (Unsupervised learning): No label or target value given for the data
# [3].å¼·åŒ–å­¸ç¿’ (Reinforcement learning):  ç‚ºäº†é”æˆç›®æ¨™,  éš¨è‘—ç’°å¢ƒçš„è®Šå‹•, è€Œé€æ­¥èª¿æ•´å…¶è¡Œç‚º, ä¸¦è©•ä¼°æ¯ä¸€å€‹è¡Œå‹•ä¹‹å¾Œæ‰€åˆ°çš„å›é¥‹æ˜¯æ­£å‘çš„æˆ–è² å‘çš„. ä¾‹: å°„æ“ŠéŠæˆ².

# 4.æ·±åº¦å­¸ç¿’ (DL, deep learning)2006~
# https://en.wikipedia.org/wiki/Deep_learning
# 2006å¹´Geoffrey Hinton (æ·±åº¦å­¸ç¿’ä¹‹çˆ¶) æˆåŠŸè¨“ç·´å¤šå±¤ç¥ç¶“ç¶²è·¯(é™åˆ¶ç»çˆ¾èŒ²æ›¼æ©Ÿ, RBM)ä¸¦å‘½åç‚ºæ·±åº¦å­¸ç¿’.

# 5.ç”Ÿæˆå­¸ç¿’ (GL, generative learning)2020,2022(ChatGPT)~
# https://en.wikipedia.org/wiki/Generative_artificial_intelligence
# 2020å¹´3æœˆï¼Œç”±ä¸€ä½åŒ¿åçš„éº»çœç†å·¥å­¸é™¢ç ”ç©¶å“¡æ‰€å‰µé€ çš„15.aiï¼Œæ˜¯ä¸€å€‹å…è²»çš„ç¶²è·¯æ‡‰ç”¨ç¨‹å¼ï¼Œå¯ä»¥ä½¿ç”¨æœ€å°‘çš„è¨“ç·´è³‡æ–™ï¼Œç”¢ç”Ÿä»¤äººä¿¡æœçš„è§’è‰²èªéŸ³ã€‚è©²å¹³å°è¢«èªç‚ºæ˜¯ç¬¬ä¸€å€‹åœ¨ç¶²è·¯è¿·å› å’Œå…§å®¹å‰µä½œä¸­æ™®åŠAIèªéŸ³å…‹éš†ï¼ˆéŸ³è¨Šæ·±åº¦å½é€ ï¼‰çš„ä¸»æµæœå‹™ï¼Œå½±éŸ¿äº†èªéŸ³AIæŠ€è¡“çš„å¾ŒçºŒç™¼å±•ã€‚

# æ©Ÿå™¨å­¸ç¿’å¸¸ç”¨æŠ€è¡“:
# Session \ Restart R

library(collapsibleTree)

ml <- c(
  "è¿´æ­¸åˆ†æ Regression analysis",
  "å»£ç¾©ç·šæ€§æ¨¡å‹ General linear model (GLM)",
  "å¤©çœŸè²æ°æ³• NaÃ¯ve-Bayes",
  "Kè¿‘é„°æ³• k-nearest neighbors (KNN)",
  "æ±ºç­–æ¨¹ Decision tree",
  "éš¨æ©Ÿæ£®æ—æ³• Random Forest",
  "æ”¯æŒå‘é‡æ©Ÿ Support vector machine (SVM)",
  "é¡ç¥ç¶“ç¶²è·¯ Neural network (NN)",
  "é›†æˆå­¸ç¿’ Ensemble learning")

uml <- c(
  "é›†ç¾¤æ³• Clustering",
  "é—œè¯è¦å‰‡ Association rule",
  "ä¸»æˆåˆ†åˆ†æ Principal Component Analysis")

æ©Ÿå™¨å­¸ç¿’ <- data.frame(type = c(rep("ç›£ç£å¼å­¸ç¿’", 9), rep("éç›£å¼ç£å­¸ç¿’", 3)),
                 algorithm = c(ml, uml))

# å»ºç«‹tree
p <- collapsibleTree(æ©Ÿå™¨å­¸ç¿’, c("type", "algorithm"), collapsed = FALSE, fontSize=12)
p

# å„²å­˜tree
library(htmlwidgets)
saveWidget(p, file="machinelearning_interactive.html")

# ğŸŒ¸ 4.1.2 CRISP-DMæ¨™æº–æµç¨‹ -----

# è·¨ç”¢æ¥­è³‡æ–™æ¢å‹˜æ¨™æº–ä½œæ¥­æµç¨‹ (CRoss Industry Standard Process for Data Mining)
# CRISP-DMæ˜¯è³‡æ–™æ¢å‹˜çš„ä¸€ç¨®æ–¹æ³•è«–.
# CRISP-DMæ–¼1990å¹´èµ·, ç”±SPSSä»¥åŠNCRå…©å¤§å» å•†åœ¨åˆä½œæˆ´å§†å…‹èŠæ–¯å‹’-è³“å£«(Daimler Benz)çš„è³‡æ–™å€‰å„²èˆ‡è³‡æ–™æ¢å‹˜éç¨‹ä¸­ç™¼å±•å‡ºä¾†çš„æ¨™æº–æµç¨‹.

library(ggflowchart)  # ç¹ªè£½æµç¨‹åœ–
library(RColorBrewer) # èª¿è‰²ç›¤
library(ggplot2)      # åœ–å½¢æ–‡æ³•ç¹ªåœ–

display.brewer.all(colorblindFriendly=TRUE) # é¡¯ç¤ºæ‰€æœ‰èª¿è‰²ç›¤
display.brewer.pal(n=6, name="Dark2")       # é¡¯ç¤ºç‰¹å®šèª¿è‰²ç›¤
datacol <- brewer.pal(n=6, name="Dark2")    # ä½¿ç”¨Set2èª¿è‰²ç›¤

# å»ºç«‹æµç¨‹åœ–å…ƒç´ 

step1 <- "æ­¥é©Ÿ1-å•†æ¥­ç†è§£"
step2 <- "æ­¥é©Ÿ2-è³‡æ–™ç†è§£"
step3 <- "æ­¥é©Ÿ3-è³‡æ–™æº–å‚™"
step4 <- "æ­¥é©Ÿ4-æ¨¡å¼å»ºç«‹"
step5 <- "æ­¥é©Ÿ5-è©•ä¼°èˆ‡æ¸¬è©¦"
step6 <- "æ­¥é©Ÿ6-ä½ˆç½²æ‡‰ç”¨"

# å»ºç«‹è³‡æ–™é›†
df <- tibble::tibble(from = c(step1, step2, step3, step4, step5),
                     to   = c(step2, step3, step4, step5, step6))

# é¡¯ç¤ºCRISP-DMæ¨™æº–æµç¨‹
ggflowchart(df, colour = datacol, text_size = 8) +
  ggtitle("CRISP-DMæ¨™æº–æµç¨‹") +
  theme(plot.title = element_text(hjust = 0.5, size = 30, face = "bold"))

# CRISP-DMæ¨™æº–æµç¨‹å…­å¤§æ­¥é©Ÿ

# æ­¥é©Ÿ1-å•†æ¥­ç†è§£
# çµ‚æ¥µç›®æ¨™æ˜¯è¦è§£æ±ºå…·é«”çš„ç”¢æ¥­å•é¡Œ, è«¸å¦‚æé«˜è³¼è²·ç‡, æ‰¾å‡ºè©æ¬ºäº¤æ˜“, éŠ·å”®é æ¸¬èˆ‡ç•°å¸¸åµæ¸¬ç­‰. å› æ­¤ä»¥å°ˆæ¥­çŸ¥è­˜ (domain knowledge)é€²è¡Œå•†æ¥­ç†è§£æ˜¯é‡è¦çš„ç¬¬ä¸€æ­¥.
# è™•ç†é‡é»ï¼šæ“¬å®šå•†æ¥­ç›®æ¨™, é€²è¡Œç•¶å‰è™•å¢ƒè©•ä¼°, æ±ºå®šè³‡æ–™æ¢å‹˜ç›®æ¨™/æˆæœ¬, ç”¢ç”Ÿå°ˆæ¡ˆè¨ˆåŠƒ, è§£æ±ºé¡§å®¢å•é¡Œ.

# æ­¥é©Ÿ2-è³‡æ–™ç†è§£
# åŒ…æ‹¬æè¿°è³‡æ–™, æ¢ç´¢å¼è³‡æ–™åˆ†æ, æ ¸é©—è³‡æ–™å“è³ª 
# æ•˜è¿°çµ±è¨ˆåˆ†æ
# å…­åŠ›åˆ†æ(summaryå‡½æ•¸)
# ç¹ªåœ–: 
# [1]ä¾ç¾¤çµ„ç‰¹æ€§
# [2]ä¾æ™‚é–“ç‰¹æ€§
# [3]æ–°å¢è©•ä¼°æ¬„ä½
# [4]è¶¨å‹¢
# [5]é›¢ç¾¤å€¼ (outlier)
# [6]æ•£ä½ˆåœ–ã€æ•£ä½ˆåœ–çŸ©é™£
# [7]ç›’é¬šåœ–

# æ­¥é©Ÿ3-è³‡æ–™æº–å‚™
# è³‡æ–™æº–å‚™æœƒå°‡è³‡æ–™éš¨æ©ŸæŠ½æ¨£å€åˆ†ç‚º[1]è¨“ç·´è³‡æ–™70ï¼… [2]æ¸¬è©¦è³‡æ–™30ï¼….
# https://github.com/rwepa/r_data_scientist/blob/main/r_training_advanced_ppt_codes_2025/images/data_preparation.png

# æ­¥é©Ÿ4-æ¨¡å¼å»ºç«‹
# https://github.com/rwepa/r_data_scientist/blob/main/r_training_advanced_ppt_codes_2025/images/modeling_evaluation.png

# æ­¥é©Ÿ5-è©•ä¼°èˆ‡æ¸¬è©¦
# https://github.com/rwepa/r_data_scientist/blob/main/r_training_advanced_ppt_codes_2025/images/modeling_evaluation.png

# æ­¥é©Ÿ6-ä½ˆç½²æ‡‰ç”¨
# https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining

# ğŸŒ¸ 4.1.3 æ¨¡å‹ç¸¾æ•ˆè©•ä¼° -----

# [1]æ•¸å€¼æ¨¡å‹ç¸¾æ•ˆæŒ‡æ¨™: åŒ…æ‹¬MSE, RMSE, MAE
# æ•´é«”èª¤å·®ä¸å¯ç›´æ¥ä½¿ç”¨èª¤å·®çš„ç®—è¡“å¹³å‡!
# å‡æ–¹èª¤å·® (Mean Squared Error, MSE) 
# å‡æ–¹æ ¹èª¤å·® (Root Mean Squared Error, RMSE) 
# å¹³å‡çµ•å°èª¤å·® (Mean Absolute Error, MAE)
# https://rwepa.blogspot.com/2013/01/rocr-roc-curve.html

# [2]é¡åˆ¥æ¨¡å‹ç¸¾æ•ˆæŒ‡æ¨™: ä½¿ç”¨æ··æ·†çŸ©é™£ (Confusion matrix)
# https://rwepa.blogspot.com/2013/01/rocr-roc-curve.html

# è¿´æ­¸æ¨¡å‹

# lm: Linear Model ç·šæ€§è¿´æ­¸æ¨¡å‹

# glm: Generalized Linear Models å»£ç¾©ç·šæ€§æ¨¡å‹, åŒ…æ‹¬é‚è¼¯æ–¯è¿´æ­¸, åœç“¦æ¾è¿´æ­¸.
# é‚è¼¯æ–¯è¿´æ­¸(Logistic regression), Yæ˜¯1å€‹é¡åˆ¥å‹è®Šæ•¸, åƒæ•¸ family = binomial()
# åœç“¦æ¾è¿´æ­¸(Poisson regression), Yæ˜¯1å€‹è¨ˆæ•¸å‹è®Šæ•¸, åƒæ•¸ family = poisson()

# é‚è¼¯æ–¯è¿´æ­¸ï¼ˆLogistic Regressionï¼‰æ•¸å­¸æ¨¡å‹

# å…¬å¼1ï¼šé‚è¼¯å‡½æ•¸ (Logistic function)
# p = e^(Î± + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + â‹¯ + Î²â‚–xâ‚–) / (1 + e^(Î± + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + â‹¯ + Î²â‚–xâ‚–))
expr1 <- expression(
  p == frac(e^(alpha + beta[1]*x[1] + beta[2]*x[2] + cdots + beta[k]*x[k]),
            1 + e^(alpha + beta[1]*x[1] + beta[2]*x[2] + cdots + beta[k]*x[k]))
)

# å…¬å¼2ï¼šå°æ•¸å‹ç®— (log odds) è½‰æ› (Logit Function)
# log(p / (1 - p)) = Î± + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + â‹¯ + Î²â‚–xâ‚–
# å·¦å´è¡¨ç¤ºäº‹ä»¶ç™¼ç”Ÿèˆ‡ä¸ç™¼ç”Ÿçš„æ©Ÿç‡æ¯”çš„å°æ•¸ (log-odds)
expr2 <- expression(
  log(frac(p, 1 - p)) == alpha + beta[1]*x[1] + beta[2]*x[2] + cdots + beta[k]*x[k]
)

# å…¬å¼è¡¨ç¤º
plot(1, type = "n", xlab = "", ylab = "", axes = FALSE)
text(1, 1.2, expr1, cex = 1.2)
text(1, 0.8, expr2, cex = 1.2)
title(main = "é‚è¼¯æ–¯è¿´æ­¸ï¼ˆLogistic Regressionï¼‰æ•¸å­¸æ¨¡å‹")
box()

# nls: Nonlinear Least Squares éç·šæ€§æœ€å°å¹³æ–¹æ³•(éç·šæ€§è¿´æ­¸)

# loess: Local Polynomial Regression Fitting å±€éƒ¨å¤šé …å¼è¿´æ­¸

# arima: Time series æ™‚é–“åºåˆ—

# ğŸŒ¸ 4.1.4 lmå‡½æ•¸ -----

# è¿´æ­¸æ¨¡å¼çš„æ¨è«–-æœ€å°å¹³æ–¹æ³•
# https://github.com/rwepa/DataDemo/blob/master/regression_01.pdf

# marketing.R
# https://github.com/rwepa/DataDemo/blob/master/marketing.R

# ğŸŒ¸ 4.1.5 glmå‡½æ•¸ -----

# é‚è¼¯æ–¯è¿´æ­¸-ç¤¾æœƒç§‘å­¸ç ”ç©¶ affair case study

library(AER)

?Affairs # 601*9

data(Affairs, package="AER")

head(Affairs)

summary(Affairs)
# å¥³æ€§: 52%
# å°å­©: 72%
# ä¸­ä½æ•¸å¹´é½¡: 32æ­²
# ç„¡å¤–é‡è€…: 75% (451/601)
# æœ€å¤šå¤–é‡12æ¬¡: 6% (38/601)

# å¤–é‡æ¬¡æ•¸çµ±è¨ˆè¡¨, æœ€å¤š12æ¬¡
table(Affairs$affairs)

# å»ºç«‹è©•ä¼°è®Šæ•¸
Affairs$ynaffair[Affairs$affairs > 0] <- 1
Affairs$ynaffair[Affairs$affairs == 0] <- 0
Affairs$ynaffair <- factor(Affairs$ynaffair,
                           levels=c(0,1),
                           labels=c("No","Yes"))
table(Affairs$ynaffair)

# é‚è¼¯æ–¯è¿´æ­¸-ä½¿ç”¨æ‰€æœ‰è‡ªè®Šæ•¸
fit_full <- glm(ynaffair ~ gender + age + yearsmarried + children + religiousness + education + occupation + rating, data=Affairs, family=binomial())

# æ¨¡å‹æ‘˜è¦
summary(fit_full)

# é‚è¼¯æ–¯è¿´æ­¸-åˆªé™¤è¼ƒä¸é¡¯è‘—çš„4å€‹è®Šæ•¸, å³på€¼å¤§æ–¼0.05è€…å…ˆåˆªé™¤(Pr(>|z|) æ²’æœ‰æ¨™è¨»*)
fit_reduced <- glm(ynaffair ~ age + yearsmarried + religiousness + rating, 
                   data=Affairs, 
                   family=binomial())

# æ¨¡å‹æ‘˜è¦-på€¼å·²é”åˆ°é¡¯è‘—æ€§
summary(fit_reduced)

# æ¨¡å‹æ¯”è¼ƒ
# på€¼ç‚º0.2108, è¡¨ç¤ºä½¿ç”¨ fit_full æ¨¡å‹æ²’æœ‰è¼ƒ fit_reduced æ“¬åˆæ›´å¥½, å› æ­¤é¸æ“‡ fit_reduced.
anova(fit_reduced, fit_full, test="Chisq")

# æ¨¡å‹åƒæ•¸, ä¸å¯ä»¥ç›´æ¥ä½¿ç”¨è©²ä¿‚æ•¸.
coef(fit_reduced)

# é€²è¡ŒæŒ‡æ•¸è½‰æ›
exp(coef(fit_reduced))

# ä¿¡è³´å€é–“ (confidence interval)
exp(confint(fit_reduced))

# æ•æ„Ÿåº¦åˆ†æ - rating
testdata <- data.frame(rating=c(1, 2, 3, 4, 5), 
                       age=mean(Affairs$age),
                       yearsmarried=mean(Affairs$yearsmarried),
                       religiousness=mean(Affairs$religiousness))
testdata
testdata$prob <- predict(fit_reduced, newdata=testdata, type="response")
testdata

# æ•æ„Ÿåº¦åˆ†æ - age
testdata <- data.frame(rating=mean(Affairs$rating),
                       age=seq(17, 57, 10),
                       yearsmarried=mean(Affairs$yearsmarried),
                       religiousness=mean(Affairs$religiousness))
testdata
testdata$prob <- predict(fit_reduced, newdata=testdata, type="response")
testdata

# ğŸŒ¸ 4.2 ç†Ÿæ‚‰é–‹æ”¾è³‡æ–™é›†æ–¼lmèˆ‡glmæ‡‰ç”¨ -----

# lmæ‡‰ç”¨ -----

data(iris)

iris_lm <- lm(Petal.Length ~ Sepal.Length, data = iris)

# æ¨¡å‹æ‘˜è¦
summary(iris_lm)

# ç¹ªåœ–
plot(iris$Sepal.Length, iris$Petal.Length,
     main = "ç·šæ€§è¿´æ­¸ - èŠ±è¼é•·åº¦ vs èŠ±ç“£é•·åº¦",
     xlab = "èŠ±è¼é•·åº¦", 
     ylab = "èŠ±ç“£é•·åº¦",
     pch = 16,
     col = iris$Species)
abline(iris_lm, col = "blue", lwd = 2)

# glmæ‡‰ç”¨ -----

# æ–°å¢äºŒå…ƒè®Šæ•¸ï¼šæ˜¯å¦ç‚º setosa
iris$IsSetosa <- ifelse(iris$Species == "setosa", 1, 0)

# é‚è¼¯æ–¯è¿´æ­¸æ¨¡å‹ï¼ˆä»¥èŠ±ç“£é•·åº¦é æ¸¬ï¼‰
glm_model <- glm(IsSetosa ~ Petal.Length, data = iris, family = binomial)

# æ¨¡å‹æ‘˜è¦
summary(glm_model)

# é æ¸¬æ©Ÿç‡
predicted_prob <- predict(glm_model, type = "response")

# Try: åŠ å…¥å…¶ä»–è®Šæ•¸

# æ±ºç­–æ¨¹-party å¥—ä»¶ -----
library(party)

str(iris)
set.seed(1234)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]

# model formula
myFormula <- Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width

# build tree
iris_ctree <- ctree(myFormula, data=trainData)

# check the prediction
table(predict(iris_ctree), trainData$Species)

# plot tree
print(iris_ctree)
plot(iris_ctree)
plot(iris_ctree, type="simple")

# predict on test data
testPred <- predict(iris_ctree, newdata = testData)
table(testPred, testData$Species)

# è®€å–ç¯€é»è³‡æ–™
nodes(iris_ctree, 3)
nodes(iris_ctree, 4)[1]
nodes(iris_ctree, 4)[[1]]
names(nodes(iris_ctree, 4)[1])
names(nodes(iris_ctree, 4)[[1]])
nodes(iris_ctree, 5)[[1]]$prediction
nodes(iris_ctree, 6)[[1]]$prediction

# éš¨æ©Ÿæ£®æ—æ³•-randomForestå¥—ä»¶ -----
library(randomForest)

ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]

iris.rf <- randomForest(Species ~ ., data=trainData, ntree=100, proximity=TRUE)
table(predict(iris.rf), trainData$Species)

print(iris.rf)
attributes(iris.rf)

# Error rates with various number of trees
plot(iris.rf)

# Extract variable importance measure
importance(iris.rf) # Gini index
varImpPlot(iris.rf)

# Test the built random forest on test data
irisPred <- predict(iris.rf, newdata=testData)
table(irisPred, testData$Species)
# end

# é¡ç¥ç¶“ç¶²è·¯-nnetå¥—ä»¶ (1å€‹éš±è—å±¤) -----

# nnet å¥—ä»¶(1å€‹éš±è—å±¤)
library(devtools)
library(nnet)

# å€åˆ†ç‚ºè¨“ç·´é›†,æ¸¬è©¦é›†
set.seed(168)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind == 1,]
testData <- iris[ind == 2,]

# å»ºç«‹æ¨¡å‹
iris.nnet <- nnet(formula = Species ~ .,
                  linout = TRUE,
                  size = 3, 
                  decay = 0.001, 
                  maxit = 1000,
                  data = trainData)

# è³‡æ–™æ‘˜è¦
summary(iris.nnet)

# ç¹ªåœ–
library(NeuralNetTools)
plotnet(iris.nnet, alpha=0.6)

# é æ¸¬-æ¸¬è©¦é›† 
irisPred.nnet <- predict(iris.nnet, testData, type = "class")

#é æ¸¬çµæœ-æ··æ·†çŸ©é™£(Confusion Matrix)
cm <- table(x = irisPred.nnet,
            y = testData$Species, 
            dnn = c("é æ¸¬", "å¯¦éš›"))
cm

# é¡ç¥ç¶“ç¶²è·¯-neuralnet å¥—ä»¶ (å¤šå€‹éš±è—å±¤) -----
library(neuralnet)

# è³‡æ–™æ•´ç†
data <- iris
data$setosa <- ifelse(data$Species == "setosa", 1, 0)
data$versicolor <- ifelse(data$Species == "versicolor", 1, 0)
data$virginica <- ifelse(data$Species == "virginica", 1, 0)
head(data)

# å€åˆ†ç‚ºè¨“ç·´é›†,æ¸¬è©¦é›†
set.seed(168)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- data[ind == 1,]
testData <- data[ind == 2,]

# å»ºç«‹æ¨¡å‹
f1 <- as.formula("setosa + versicolor + virginica  ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width")
bpn <- neuralnet(formula = f1, 
                 data = trainData, 
                 hidden = c(2, 4), # 2å€‹éš±è—å±¤, ç¯€é»æ•¸åˆ†åˆ¥ç‚º2, 4
                 learningrate = 0.01)
print(bpn)

# ğŸŒ¸ 4.3 æ·±åº¦å­¸ç¿’æ‡‰ç”¨ -----

# ä½¿ç”¨åŸç”Ÿ torch å¥—ä»¶
# https://cran.r-project.org/web/packages/torch/
# https://torch.mlverse.org/docs/

# ğŸŒ¸ åƒè€ƒè³‡æ–™ -----

# RWEPA
# http://rwepa.blogspot.com/

# iPAS-R-tutorial
# https://github.com/rwepa/ipas_bda/blob/main/ipas-r-program.R

# Rå…¥é–€è³‡æ–™åˆ†æèˆ‡è¦–è¦ºåŒ–æ‡‰ç”¨æ•™å­¸(ä»˜è²»)
# https://mastertalks.tw/products/r?ref=MCLEE

# Rå•†æ¥­é æ¸¬èˆ‡æ‡‰ç”¨(ä»˜è²»)
# https://mastertalks.tw/products/r-2?ref=MCLEE 
# end
# è¬è¬æ‚¨çš„è†è½ , Q & A